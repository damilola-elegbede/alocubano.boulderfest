---
name: 🎭 E2E Tests - Preview Deployments

# Modern E2E testing workflow using Vercel Preview Deployments
# - Triggers ONLY on successful Vercel deployments to prevent duplicate runs
# - Real production environment testing with serverless functions  
# - No local server management or port conflicts
# - Improved reliability and faster execution
# - Single run per deployment with deployment_status trigger

on:
  # Only trigger when Vercel deployments succeed - prevents duplicate runs
  deployment_status:
    # Trigger when Vercel deployments succeed
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'standard'
        type: choice
        options:
          - 'standard'      # Basic flows (6 tests)
          - 'advanced'      # All flows (12 tests)
          - 'performance'   # Performance-focused tests
          - 'accessibility' # Mobile experience tests
          - 'security'      # Admin and security tests
      browsers:
        description: 'Browser matrix to test'
        required: false
        default: 'standard'
        type: choice
        options:
          - 'standard'      # Chromium + Firefox
          - 'extended'      # + Safari (WebKit)
          - 'mobile'        # + Mobile browsers
          - 'chromium-only' # Chromium only (fastest)
      preview_url:
        description: 'Specific preview URL to test (optional)'
        required: false
        type: string

# Prevent multiple E2E runs for the same deployment
concurrency:
  group: e2e-preview-${{ github.event.deployment.sha || github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write
  deployments: read

env:
  NODE_VERSION: "20"
  NODE_ENV: test
  CI: true
  NODE_OPTIONS: '--max-old-space-size=3072'
  PLAYWRIGHT_BROWSERS_PATH: ${{ github.workspace }}/.playwright-browsers

jobs:
  # Extract preview URL - simplified since deployment is already complete
  get-preview-url:
    name: 🔍 Extract Preview URL
    runs-on: ubuntu-latest
    if: >-
      (github.event_name == 'deployment_status' &&
       github.event.deployment_status.state == 'success' &&
       github.event.deployment.environment == 'Preview') ||
      (github.event_name == 'workflow_dispatch')
    outputs:
      preview-url: ${{ steps.extract-url.outputs.preview-url }}
    steps:
      - name: 🔍 Extract Preview URL
        id: extract-url
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ -n "${{ inputs.preview_url }}" ]; then
            # Manual trigger with specific URL
            echo "preview-url=${{ inputs.preview_url }}" >> $GITHUB_OUTPUT
            echo "ℹ️ Using manually provided URL: ${{ inputs.preview_url }}"
          elif [ "${{ github.event_name }}" = "deployment_status" ]; then
            # Triggered by deployment_status event - deployment is already complete
            DEPLOYMENT_URL="${{ github.event.deployment_status.target_url }}"
            echo "preview-url=$DEPLOYMENT_URL" >> $GITHUB_OUTPUT
            echo "ℹ️ Using deployment status URL: $DEPLOYMENT_URL"
          else
            echo "❌ Unexpected event type: ${{ github.event_name }}"
            exit 1
          fi

      - name: 📋 URL Extraction Summary
        run: |
          echo "🎯 Preview URL Extraction Results:"
          echo "  Event: ${{ github.event_name }}"
          echo "  URL: ${{ steps.extract-url.outputs.preview-url }}"
          echo "  Deployment State: ${{ github.event.deployment_status.state || 'N/A' }}"
          echo "  Environment: ${{ github.event.deployment.environment || 'N/A' }}"


  # Build test matrix (runs in parallel with URL extraction)
  build-test-matrix:
    name: 📋 Build Test Matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.matrix.outputs.matrix }}
      test-pattern: ${{ steps.matrix.outputs.test-pattern }}
    steps:
      - name: 🧮 Build Test Matrix
        id: matrix
        run: |
          # Determine browser matrix
          BROWSER_MATRIX='["chromium"]' # Default fallback

          case "${{ inputs.browsers || 'standard' }}" in
            "standard")
              BROWSER_MATRIX='["chromium", "firefox"]'
              ;;
            "extended")
              BROWSER_MATRIX='["chromium", "firefox", "webkit"]'
              ;;
            "mobile")
              BROWSER_MATRIX='["chromium", "firefox", "mobile-chrome", "mobile-safari"]'
              ;;
            "chromium-only")
              BROWSER_MATRIX='["chromium"]'
              ;;
          esac

          # Determine test pattern
          TEST_PATTERN=""
          case "${{ inputs.test_suite || 'standard' }}" in
            "standard")
              TEST_PATTERN="basic-navigation|cart-functionality|newsletter-simple|admin-auth|gallery-basic|registration-flow"
              ;;
            "advanced")
              TEST_PATTERN="" # Run all tests
              ;;
            "performance")
              TEST_PATTERN="performance|gallery-browsing|user-engagement"
              ;;
            "accessibility")
              TEST_PATTERN="mobile-registration|accessibility"
              ;;
            "security")
              TEST_PATTERN="admin-auth|admin-dashboard|ticket-validation"
              ;;
          esac

          echo "matrix={\"browser\":$BROWSER_MATRIX}" >> $GITHUB_OUTPUT
          echo "test-pattern=$TEST_PATTERN" >> $GITHUB_OUTPUT

          echo "📋 Test Matrix Configuration:"
          echo "  Browsers: $BROWSER_MATRIX"
          echo "  Test Pattern: $TEST_PATTERN"

  # Main E2E testing job - simplified since deployment is already complete
  e2e-tests:
    name: 🎭 E2E Tests (${{ matrix.browser }})
    runs-on: ubuntu-latest
    needs: [get-preview-url, build-test-matrix]
    # Only run if URL extraction succeeded
    if: needs.get-preview-url.result == 'success'
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.build-test-matrix.outputs.matrix) }}
    timeout-minutes: 20

    steps:
      - name: 📥 Checkout
        uses: actions/checkout@v4

      - name: 🎯 Set Target URL
        id: target-url
        run: |
          TARGET_URL="${{ needs.get-preview-url.outputs.preview-url }}"
          
          # Validate we have a URL
          if [ -z "$TARGET_URL" ] || [ "$TARGET_URL" = "null" ]; then
            echo "❌ No valid preview URL available"
            exit 1
          fi
          
          echo "target-url=$TARGET_URL" >> $GITHUB_OUTPUT
          echo "PLAYWRIGHT_BASE_URL=$TARGET_URL" >> $GITHUB_ENV
          echo "PREVIEW_URL=$TARGET_URL" >> $GITHUB_ENV
          echo "ℹ️ Using preview URL: $TARGET_URL"

      - name: 📋 Test Configuration
        run: |
          echo "🎯 E2E Test Configuration:"
          echo "  Target URL: ${{ steps.target-url.outputs.target-url }}"
          echo "  Browser: ${{ matrix.browser }}"
          echo "  Test Suite: ${{ inputs.test_suite || 'standard' }}"
          echo "  Test Pattern: ${{ needs.build-test-matrix.outputs.test-pattern }}"
          echo "  NODE_OPTIONS: $NODE_OPTIONS"
          echo "  Event Type: ${{ github.event_name }}"
          echo "  Deployment State: ${{ github.event.deployment_status.state || 'N/A' }}"

      - name: 🟢 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'package-lock.json'

      - name: 📦 Install Dependencies
        run: |
          npm ci --prefer-offline --no-audit
          echo "✅ Dependencies installed"

      - name: 🧩 Cache Playwright Browsers
        uses: actions/cache@v4
        with:
          path: .playwright-browsers
          key: ${{ runner.os }}-pw-${{ matrix.browser }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-pw-${{ matrix.browser }}-
            ${{ runner.os }}-pw-

      - name: 🎭 Install Playwright Browsers
        run: |
          # Map mobile browsers to actual browser names
          BROWSER="${{ matrix.browser }}"
          case "$BROWSER" in
            mobile-chrome) INSTALL_BROWSER="chromium" ;;
            mobile-safari) INSTALL_BROWSER="webkit" ;;
            *) INSTALL_BROWSER="$BROWSER" ;;
          esac

          # Always verify browser installation for reliability
          echo "🔍 Verifying Playwright browser: $INSTALL_BROWSER..."
          
          # Check if browser is properly installed and functional
          if ! npx playwright install --dry-run "$INSTALL_BROWSER" 2>/dev/null; then
            echo "🔄 Installing Playwright browser: $INSTALL_BROWSER..."
            npx playwright install --with-deps "$INSTALL_BROWSER"
            
            # Verify installation succeeded
            if ! npx playwright install --dry-run "$INSTALL_BROWSER" 2>/dev/null; then
              echo "❌ Browser installation failed for: $INSTALL_BROWSER"
              exit 1
            fi
          else
            echo "✅ Browser already installed: $INSTALL_BROWSER"
          fi

      - name: 🎭 Run E2E Tests
        run: |
          TEST_COMMAND="npm run test:e2e -- --project ${{ matrix.browser }}"

          # Add test pattern filter if specified
          if [ -n "${{ needs.build-test-matrix.outputs.test-pattern }}" ]; then
            # Use grep pattern matching to filter specific tests
            TEST_COMMAND="$TEST_COMMAND --grep \"${{ needs.build-test-matrix.outputs.test-pattern }}\""
            echo "🎯 Test pattern filter: ${{ needs.build-test-matrix.outputs.test-pattern }}"
          fi

          echo "🚀 Running: $TEST_COMMAND"
          echo "🌐 Target URL: ${{ env.PREVIEW_URL }}"
          echo "🦊 Browser: ${{ matrix.browser }}"
          
          # Run tests with better error handling
          if ! eval $TEST_COMMAND; then
            echo "❌ E2E tests failed for ${{ matrix.browser }}"
            echo "📊 Collecting debug information..."
            
            # List available test files for debugging
            echo "Available test files:"
            find tests/e2e/flows -name "*.test.js" | head -10
            
            exit 1
          fi
        env:
          PLAYWRIGHT_BASE_URL: ${{ env.PREVIEW_URL }}

      - name: 📊 Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-results-${{ matrix.browser }}
          path: |
            playwright-report/
            test-results/
          retention-days: 7

      - name: 📋 Test Summary
        if: always()
        run: |
          echo "📊 E2E Test Summary (${{ matrix.browser }}):"
          echo "  Target URL: ${{ env.PREVIEW_URL }}"
          echo "  Test Status: ${{ job.status }}"
          echo "  Browser: ${{ matrix.browser }}"
          
          # Firefox-specific debugging information
          if [ "${{ matrix.browser }}" = "firefox" ]; then
            echo "🦊 Firefox-specific debug information:"
            echo "  Firefox timeout: 20s actions, 45s navigation"
            echo "  User Agent: Playwright-E2E-Tests-Preview-Firefox"
            
            # Check if there were any firefox-specific timeouts
            if [ -f "test-results" ]; then
              echo "  Timeout errors:"
              find test-results -name "*.txt" -exec grep -l "timeout\|TimeoutError" {} \; 2>/dev/null || echo "    No timeout errors found"
            fi
          fi
          
          if [ -f "playwright-report/index.html" ]; then
            echo "  Report: Available in artifacts"
            
            # Count test results for summary
            TOTAL_TESTS=$(find test-results -name "*.zip" 2>/dev/null | wc -l || echo "0")
            echo "  Test artifacts: $TOTAL_TESTS"
          fi

  # Collect and report results
  e2e-results:
    name: 📊 E2E Results Summary
    runs-on: ubuntu-latest
    needs: [e2e-tests, build-test-matrix]
    if: always()
    steps:
      - name: 📥 Checkout
        uses: actions/checkout@v4

      - name: 📊 Collect Test Results
        id: collect
        uses: ./.github/actions/collect-test-results
        with:
          test-type: "e2e"
          test-results-path: "test-results-summary.json"

      - name: 📄 Read Summary JSON
        id: read-results
        run: |
          echo "json=$(jq -c . test-results-summary.json 2>/dev/null || echo '{}')" >> "$GITHUB_OUTPUT"

      - name: 💬 Post Results to PR
        if: github.event_name == 'deployment_status' && github.event.deployment.environment == 'Preview'
        uses: ./.github/actions/post-test-comment
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          commit-sha: ${{ github.sha }}
          workflow-run-id: ${{ github.run_id }}
          e2e-test-results: ${{ steps.read-results.outputs.json }}

      - name: 📋 Final Summary
        run: |
          echo "🎯 E2E Test Suite Complete"
          echo "  Suite: ${{ inputs.test_suite || 'standard' }}"
          echo "  Browsers: ${{ inputs.browsers || 'standard' }}"
          echo "  Status: ${{ needs.e2e-tests.result }}"

          if [ "${{ needs.e2e-tests.result }}" = "success" ]; then
            echo "✅ All E2E tests passed!"
          else
            echo "❌ Some E2E tests failed - check individual job results"
            exit 1
          fi