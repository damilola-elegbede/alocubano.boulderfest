name: "ðŸ”— Integration Tests"

on:
  pull_request:
    branches: [main, develop]
    types: [opened, synchronize, reopened]
    paths:
      - 'api/**'
      - 'js/**'
      - 'css/**'
      - 'pages/**'
      - 'tests/integration/**'
      - 'package.json'
      - 'vitest*.config.js'
      - 'tests/config/**'
  push:
    branches: [main, develop]
    paths:
      - 'api/**'
      - 'js/**'
      - 'css/**'
      - 'pages/**'
      - 'tests/integration/**'
      - 'package.json'
      - 'vitest*.config.js'
      - 'tests/config/**'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Integration test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - 'all'         # All integration tests
          - 'api'         # API integration tests only
          - 'database'    # Database integration tests only
          - 'services'    # Service integration tests only
          - 'critical'    # Critical payment integration tests

concurrency:
  group: integration-tests-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write

env:
  NODE_VERSION: "20"
  NODE_ENV: test
  CI: true
  NODE_OPTIONS: "--max-old-space-size=4096"

jobs:
  # Path-based test planning to avoid unnecessary runs
  test-planning:
    name: "ðŸ“‹ Test Planning"
    runs-on: ubuntu-latest
    timeout-minutes: 10  # Increased from 5 to allow for slower CI environments
    outputs:
      should_run: ${{ steps.planning.outputs.should_run }}
      test_suite: ${{ steps.planning.outputs.test_suite }}
      test_pattern: ${{ steps.planning.outputs.test_pattern }}
    
    steps:
      - name: "ðŸ“¥ Checkout Code"
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: "ðŸ” Detect Changes"
        uses: dorny/paths-filter@v3
        id: changes
        with:
          filters: |
            frontend:
              - 'js/**'
              - 'css/**'
              - 'pages/**'
            backend:
              - 'api/**'
            integration:
              - 'tests/integration/**'
            config:
              - 'vitest*.config.js'
              - 'tests/config/**'
              - 'package.json'

      - name: "ðŸ“‹ Plan Test Execution"
        id: planning
        run: |
          # Determine if tests should run
          SHOULD_RUN="false"
          TEST_SUITE="${{ inputs.test_suite || 'all' }}"
          TEST_PATTERN="tests/integration/**/*.test.js"
          
          # Run tests if relevant changes detected or manual trigger
          if [ "${{ steps.changes.outputs.frontend }}" == "true" ] || 
             [ "${{ steps.changes.outputs.backend }}" == "true" ] || 
             [ "${{ steps.changes.outputs.integration }}" == "true" ] || 
             [ "${{ steps.changes.outputs.config }}" == "true" ] || 
             [ "${{ github.event_name }}" == "workflow_dispatch" ] ||
             [ "${{ github.event_name }}" == "push" ]; then
            SHOULD_RUN="true"
          fi
          
          # Set test patterns based on suite selection
          case "$TEST_SUITE" in
            "api")
              TEST_PATTERN="tests/integration/api/**/*.test.js"
              ;;
            "database")
              TEST_PATTERN="tests/integration/database/**/*.test.js"
              ;;
            "services")
              TEST_PATTERN="tests/integration/services/**/*.test.js"
              ;;
            "critical")
              TEST_PATTERN="tests/integration/core/**/*.test.js"
              ;;
            *)
              TEST_PATTERN="tests/integration/**/*.test.js"
              ;;
          esac
          
          # Optimize for draft PRs (run critical tests only)
          if [ "${{ github.event.pull_request.draft }}" == "true" ] && [ "${{ github.event_name }}" == "pull_request" ]; then
            TEST_SUITE="critical"
            TEST_PATTERN="tests/integration/core/**/*.test.js"
          fi
          
          echo "should_run=$SHOULD_RUN" >> $GITHUB_OUTPUT
          echo "test_suite=$TEST_SUITE" >> $GITHUB_OUTPUT
          echo "test_pattern=$TEST_PATTERN" >> $GITHUB_OUTPUT
          
          echo "ðŸŽ¯ Integration Test Planning:"
          echo "  Will run: $SHOULD_RUN"
          echo "  Test suite: $TEST_SUITE"
          echo "  Test pattern: $TEST_PATTERN"

  # Integration Tests with Vitest
  integration-tests:
    name: "ðŸ”— Integration Tests"
    runs-on: ubuntu-latest
    needs: test-planning
    if: needs.test-planning.outputs.should_run == 'true'
    timeout-minutes: 20  # Increased from 10 to 20 minutes for comprehensive integration testing
    outputs:
      total_tests: ${{ steps.integration-test.outputs.total_tests }}
      passing_tests: ${{ steps.integration-test.outputs.passing_tests }}
      failing_tests: ${{ steps.integration-test.outputs.failing_tests }}
      duration: ${{ steps.integration-test.outputs.duration }}
    
    steps:
      - name: "ðŸ“¥ Checkout Code"
        uses: actions/checkout@v4

      - name: "ðŸ”§ Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: "ðŸ“¦ Install Dependencies"
        run: npm ci --prefer-offline --no-audit
        env:
          NGROK_SKIP_DOWNLOAD: true

      - name: "ðŸ—ƒï¸ Setup SQLite Database"
        env:
          NODE_ENV: test
          DATABASE_URL: "file:./data/integration-tests.db"
          CI: true
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ—ƒï¸ Setting up Integration Test Database"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ—ƒï¸ Database URL: $DATABASE_URL"
          
          # Create data directory if it doesn't exist
          mkdir -p data
          
          # Remove any existing integration test database
          rm -f data/integration-tests.db
          
          # Run database migrations
          echo "ðŸ”„ Running database migrations..."
          node scripts/migrate.js
          
          # Verify database creation
          if [ -f "data/integration-tests.db" ]; then
            echo "âœ… Integration test database created successfully"
            echo "ðŸ“Š Database size: $(du -h data/integration-tests.db | cut -f1)"
          else
            echo "âŒ Failed to create integration test database"
            exit 1
          fi

      - name: "ðŸ”§ Setup Test Environment"
        run: |
          mkdir -p test-results .tmp/integration
          
          # Create test environment configuration
          cat > .env.local << EOF
          NODE_ENV=test
          CI=true
          DATABASE_URL="file:./data/integration-tests.db"
          
          # Test credentials (for integration tests)
          TEST_ADMIN_PASSWORD=test-password-123
          ADMIN_SECRET=test-admin-secret-key-minimum-32-characters
          
          # Integration test timeouts - increased for CI stability
          VITEST_TEST_TIMEOUT=120000
          VITEST_HOOK_TIMEOUT=30000
          VITEST_SETUP_TIMEOUT=20000
          VITEST_CLEANUP_TIMEOUT=10000
          VITEST_REQUEST_TIMEOUT=60000
          EOF

      - name: "ðŸ”— Run Integration Tests"
        id: integration-test
        env:
          NODE_ENV: test
          DATABASE_URL: "file:./data/integration-tests.db"
          CI: true
          # Increased timeout environment variables for CI stability
          VITEST_TEST_TIMEOUT: 120000    # 2 minutes per individual test
          VITEST_HOOK_TIMEOUT: 30000     # 30 seconds for hooks
          VITEST_SETUP_TIMEOUT: 20000    # 20 seconds for setup
          VITEST_CLEANUP_TIMEOUT: 10000  # 10 seconds for cleanup
          VITEST_REQUEST_TIMEOUT: 60000  # 1 minute for HTTP requests
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ”— Running Integration Test Suite"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸŽ¯ Timeout: 20 minutes total (job limit)"
          echo "ðŸ—ƒï¸ Database: SQLite with real file storage"
          echo "ðŸŒ APIs: Limited external service integration"
          echo "ðŸ§ª Expected: ~30-50 integration tests"
          echo "âš™ï¸  Environment: Test credentials configured"
          echo "â±ï¸  Individual Test Timeout: 2 minutes"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Record start time
          start_time=$(date +%s%3N)
          
          # Configure test command based on suite
          if [ "${{ needs.test-planning.outputs.test_suite }}" == "critical" ]; then
            echo "ðŸƒâ€â™‚ï¸ Running critical integration tests (payment processing)"
            npm run test:integration:critical 2>&1 | tee integration-test-output.log || true
          else
            echo "ðŸ“‹ Running integration test suite"
            npm run test:integration 2>&1 | tee integration-test-output.log || true
          fi
          
          test_exit_code=${PIPESTATUS[0]}
          
          # Record end time
          end_time=$(date +%s%3N)
          duration=$((end_time - start_time))
          
          # Extract test counts from output - handle both 'passed' and 'passing' variants
          total_tests=$(grep -oP '\d+(?= (tests? )?passed)' integration-test-output.log | head -1 || echo "0")
          passing_tests=$total_tests
          failing_tests=$(grep -oP '\d+(?= (tests? )?failed)' integration-test-output.log | head -1 || echo "0")
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ“Š Integration Test Results"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… Tests Passed: $passing_tests"
          echo "âŒ Tests Failed: $failing_tests"
          echo "ðŸ“ˆ Total Tests: $total_tests"
          echo "â±ï¸  Duration: ${duration}ms"
          echo "ðŸ—ƒï¸ Database: File-based SQLite"
          
          # Timeout evaluation
          if [ "$duration" -lt 1200000 ]; then  # 20 minutes in milliseconds
            echo "ðŸ† EXCELLENT: Integration tests completed within 20-minute limit!"
          else
            echo "âš ï¸  WARNING: Integration tests exceeded 20-minute timeout limit"
          fi
          
          # Set outputs for summary
          echo "total_tests=$total_tests" >> $GITHUB_OUTPUT
          echo "passing_tests=$passing_tests" >> $GITHUB_OUTPUT
          echo "failing_tests=$failing_tests" >> $GITHUB_OUTPUT
          echo "duration=${duration}ms" >> $GITHUB_OUTPUT
          
          exit $test_exit_code

      - name: "ðŸ§¹ Database Cleanup"
        if: always()
        run: |
          echo "ðŸ§¹ Cleaning up integration test database..."
          rm -f data/integration-tests.db
          echo "âœ… Integration test database cleanup completed"

      - name: "ðŸ“¤ Upload Test Results"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results-${{ github.run_number }}
          path: |
            integration-test-output.log
            integration-test-results.xml
            coverage/integration/
            .tmp/integration/
          retention-days: 7
          if-no-files-found: ignore

      - name: "ðŸ“Š Test Summary"
        if: always()
        run: |
          echo "# ðŸ”— Integration Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Suite**: ${{ needs.test-planning.outputs.test_suite }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Pattern**: ${{ needs.test-planning.outputs.test_pattern }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment**: Node.js ${{ env.NODE_VERSION }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Memory Allocation**: 4GB" >> $GITHUB_STEP_SUMMARY
          echo "- **Timeout Configuration**: 20 minutes total, 2 minutes per test" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ $? -eq 0 ]; then
            echo "### âœ… Integration Tests Passed!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All integration tests have completed successfully." >> $GITHUB_STEP_SUMMARY
            echo "Integration tests validate real database connections, API endpoints, and service interactions." >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Integration Test Failures" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Some integration tests have failed. Please review:" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "1. **Check test artifacts** for detailed failure information" >> $GITHUB_STEP_SUMMARY
            echo "2. **Run locally**: \`npm run test:integration\` to reproduce issues" >> $GITHUB_STEP_SUMMARY
            echo "3. **Check database connectivity** and service dependencies" >> $GITHUB_STEP_SUMMARY
          fi

  # Test Results Summary
  integration-summary:
    name: "ðŸ“Š Integration Test Summary"
    runs-on: ubuntu-latest
    needs: [test-planning, integration-tests]
    if: always()
    
    steps:
      - name: "ðŸ“Š Generate Test Summary"
        run: |
          echo "# ðŸ”— Integration Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.test-planning.outputs.should_run }}" == "true" ]; then
            echo "## Test Execution Status" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "- **Test Suite**: ${{ needs.test-planning.outputs.test_suite }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Test Pattern**: ${{ needs.test-planning.outputs.test_pattern }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Integration Tests**: ${{ needs.integration-tests.result == 'success' && 'âœ… Passed' || (needs.integration-tests.result == 'failure' && 'âŒ Failed' || 'â­ï¸ Skipped') }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Timeout Configuration**: 20 minutes total, 2 minutes per individual test" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ "${{ needs.integration-tests.result }}" == "success" ]; then
              echo "### âœ… Integration Tests Passed!" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "All integration tests have passed successfully." >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**What was tested:**" >> $GITHUB_STEP_SUMMARY
              echo "- Database connections and migrations" >> $GITHUB_STEP_SUMMARY
              echo "- API endpoint functionality" >> $GITHUB_STEP_SUMMARY
              echo "- Service integrations (email, payments)" >> $GITHUB_STEP_SUMMARY
              echo "- Data integrity and transactions" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**Timeout Improvements:**" >> $GITHUB_STEP_SUMMARY
              echo "- Job timeout: Increased to 20 minutes for comprehensive testing" >> $GITHUB_STEP_SUMMARY
              echo "- Individual test timeout: 2 minutes per test for complex operations" >> $GITHUB_STEP_SUMMARY
              echo "- Database operations: Extended timeouts for migrations and setup" >> $GITHUB_STEP_SUMMARY
              echo "- HTTP requests: 1 minute timeout for external service calls" >> $GITHUB_STEP_SUMMARY
            elif [ "${{ needs.integration-tests.result }}" == "failure" ]; then
              echo "### âŒ Integration Test Failures" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "Some integration tests have failed. Please review:" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "1. **Check test artifacts** for detailed failure information" >> $GITHUB_STEP_SUMMARY
              echo "2. **Run locally**: \`npm run test:integration\` to reproduce issues" >> $GITHUB_STEP_SUMMARY
              echo "3. **Check service dependencies**: Database, external APIs" >> $GITHUB_STEP_SUMMARY
              echo "4. **Review environment setup**: Database migrations, test data" >> $GITHUB_STEP_SUMMARY
              echo "5. **Verify timeouts**: Tests now have 2 minutes per test, 20 minutes total" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "- **Integration Tests**: â­ï¸ Skipped (no relevant changes detected)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### â„¹ï¸ Tests Skipped" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Integration tests were skipped because no relevant file changes were detected." >> $GITHUB_STEP_SUMMARY
            echo "Tests will run automatically when changes are made to:" >> $GITHUB_STEP_SUMMARY
            echo "- Frontend code (js/, css/, pages/)" >> $GITHUB_STEP_SUMMARY
            echo "- Backend code (api/)" >> $GITHUB_STEP_SUMMARY
            echo "- Integration test files (tests/integration/)" >> $GITHUB_STEP_SUMMARY
            echo "- Test configuration (vitest*.config.js, tests/config/)" >> $GITHUB_STEP_SUMMARY
          fi

      - name: "ðŸ’¬ Comment on PR"
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const shouldRun = '${{ needs.test-planning.outputs.should_run }}';
            const testResult = '${{ needs.integration-tests.result }}';
            const testSuite = '${{ needs.test-planning.outputs.test_suite }}';
            
            let status, statusText, summary;
            
            if (shouldRun === 'true') {
              if (testResult === 'success') {
                status = 'âœ…';
                statusText = 'PASSED';
                summary = `### ðŸŽ‰ All integration tests passed!
                
                Integration tests validate real database connections, API endpoints, and service integrations.
                
                **Test Configuration:**
                - Test Suite: ${testSuite}
                - Test Runner: Vitest
                - Environment: Node.js ${{ env.NODE_VERSION }}
                - Memory Allocation: 4GB
                - Timeout: 20 minutes total, 2 minutes per test
                
                **What was tested:**
                - Database operations and migrations
                - API endpoint functionality
                - Service integrations (email, payments)
                - Data integrity and transactions
                
                **Timeout Improvements:**
                - Job timeout increased to 20 minutes for stability
                - Individual test timeout: 2 minutes for complex operations
                - Database setup: Extended time for migrations
                - HTTP requests: 1 minute timeout for external calls`;
              } else {
                status = 'âŒ';
                statusText = 'FAILED';
                summary = `### âš ï¸ Some integration tests failed
                
                Please review the workflow output and test artifacts for details.
                
                **Debugging Steps:**
                1. Check the test artifacts for detailed failure information
                2. Run tests locally with \`npm run test:integration\`
                3. Verify database connectivity and service dependencies
                4. Review environment setup and migrations
                5. Note: Tests now have extended timeouts (20min total, 2min per test)
                
                **Timeout Configuration:**
                - Job timeout: 20 minutes (increased for CI stability)
                - Individual test timeout: 2 minutes per test
                - Database operations: Extended setup and migration time
                - HTTP requests: 1 minute timeout for external services`;
              }
            } else {
              status = 'â­ï¸';
              statusText = 'SKIPPED';
              summary = `### â„¹ï¸ Integration tests skipped
              
              No relevant changes detected. Tests will run when changes are made to:
              - Frontend code (js/, css/, pages/)
              - Backend code (api/)
              - Integration test files (tests/integration/)
              - Test configuration files`;
            }

            const comment = `## ${status} Integration Tests ${statusText}

            ${summary}

            ---
            **Workflow Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Integration Tests')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }