---
name: ðŸŽ­ Modernized E2E Testing Suite

# Modern E2E workflow using Vercel Preview Deployments:
# - Uses live Vercel preview URLs instead of local dev servers
# - No server management complexity or port conflicts
# - Production-like testing environment
# - Better CI/CD integration and reliability
# - Eliminates server hanging issues

on:
  pull_request:
    branches: [main, develop, feature/phase4-*]
    types: [opened, synchronize, reopened, ready_for_review]
  push:
    branches: [feature/phase4-*] 
  schedule:
    # Nightly comprehensive testing at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'standard'
        type: choice
        options:
          - 'standard'      # Core 12 flows
          - 'advanced'      # All 26 tests
          - 'nightly'       # Comprehensive + extended browsers
          - 'performance'   # Performance-focused tests
          - 'accessibility' # WCAG compliance tests
          - 'security'      # Security-focused tests
      test_pattern:
        description: 'Test pattern filter (e.g., "gallery" or "admin")'
        required: false
        default: ''
        type: string
      browsers:
        description: 'Browser matrix to test'
        required: false
        default: 'standard'
        type: choice
        options:
          - 'standard'     # chromium, firefox
          - 'extended'     # chromium, firefox, webkit
          - 'chromium-only' # Chromium only (fastest)

concurrency:
  group: e2e-modern-${{ github.head_ref || github.ref }}-${{ github.workflow }}
  cancel-in-progress: true

env:
  NODE_VERSION: "20"
  NODE_ENV: test
  CI: true

jobs:
  # Pre-flight validation and test planning
  validate:
    name: ðŸ” Pre-flight Validation & Test Planning
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: contains(github.head_ref, 'feature/phase4-') || github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    outputs:
      should_run_e2e: ${{ steps.planning.outputs.should_run_e2e }}
      test_suite: ${{ steps.planning.outputs.test_suite }}
      test_pattern: ${{ steps.planning.outputs.test_pattern }}
      browser_matrix: ${{ steps.planning.outputs.browser_matrix }}
      is_nightly: ${{ steps.planning.outputs.is_nightly }}
      advanced_tests_enabled: ${{ steps.planning.outputs.advanced_tests_enabled }}
      total_test_count: ${{ steps.planning.outputs.total_test_count }}
    
    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: ðŸ”§ Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Quick Dependencies Install
        run: npm ci --prefer-offline --no-audit --no-fund

      - name: ðŸ” Detect Changes & Plan Tests
        id: changes
        uses: dorny/paths-filter@v3
        with:
          filters: |
            frontend:
              - 'js/**'
              - 'css/**' 
              - 'pages/**'
            backend:
              - 'api/**'
              - 'migrations/**'
            e2e:
              - 'tests/e2e/**'
            config:
              - 'playwright*.config.js'
              - 'package.json'
              - '.github/workflows/e2e-*.yml'
        
      - name: ðŸ“‹ Advanced Test Planning & Suite Selection
        id: planning
        run: |
          # Determine if this is a nightly run
          IS_NIGHTLY="false"
          if [ "${{ github.event_name }}" == "schedule" ]; then
            IS_NIGHTLY="true"
          fi
          
          # Determine test suite based on inputs and changes
          TEST_SUITE="${{ inputs.test_suite || 'standard' }}"
          ADVANCED_TESTS_ENABLED="false"
          TOTAL_TEST_COUNT="12"
          
          # Nightly runs always include advanced tests
          if [ "$IS_NIGHTLY" == "true" ]; then
            TEST_SUITE="nightly"
            ADVANCED_TESTS_ENABLED="true"
            TOTAL_TEST_COUNT="26"
          fi
          
          # Manual selection overrides
          if [ "${{ inputs.test_suite }}" == "advanced" ] || [ "${{ inputs.test_suite }}" == "nightly" ]; then
            ADVANCED_TESTS_ENABLED="true"
            TOTAL_TEST_COUNT="26"
          fi
          
          # Determine test pattern
          TEST_PATTERN="${{ inputs.test_pattern || '' }}"
          
          # Determine browser matrix based on context
          BROWSER_MATRIX="${{ inputs.browsers || 'standard' }}"
          if [ "$IS_NIGHTLY" == "true" ]; then
            BROWSER_MATRIX="extended"
          elif [ "${{ github.event.pull_request.draft }}" == "true" ]; then
            BROWSER_MATRIX="chromium-only"
          fi
          
          # Determine if E2E tests should run
          SHOULD_RUN="true"
          
          # Only run on phase4 feature branches
          if [ "${{ github.event_name }}" == "pull_request" ] && ! echo "${{ github.head_ref }}" | grep -q "feature/phase4-"; then
            echo "Not a phase4 feature branch - skipping E2E tests"
            SHOULD_RUN="false"
          fi
          
          # Skip E2E for draft PRs unless explicit pattern provided
          if [ "${{ github.event.pull_request.draft }}" == "true" ] && [ -z "$TEST_PATTERN" ] && [ "$IS_NIGHTLY" != "true" ]; then
            echo "Draft PR detected - skipping E2E tests"
            SHOULD_RUN="false"
          fi
          
          # Skip if no relevant changes detected (except nightly/manual)
          if [ "${{ steps.changes.outputs.frontend }}" == "false" ] && 
             [ "${{ steps.changes.outputs.backend }}" == "false" ] && 
             [ "${{ steps.changes.outputs.e2e }}" == "false" ] && 
             [ "${{ steps.changes.outputs.config }}" == "false" ] &&
             [ "${{ github.event_name }}" == "pull_request" ] && 
             [ "$IS_NIGHTLY" != "true" ] &&
             [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
            echo "No relevant changes detected - skipping E2E tests"
            SHOULD_RUN="false"
          fi
          
          # Set outputs
          echo "should_run_e2e=$SHOULD_RUN" >> $GITHUB_OUTPUT
          echo "test_suite=$TEST_SUITE" >> $GITHUB_OUTPUT
          echo "test_pattern=$TEST_PATTERN" >> $GITHUB_OUTPUT
          echo "browser_matrix=$BROWSER_MATRIX" >> $GITHUB_OUTPUT
          echo "is_nightly=$IS_NIGHTLY" >> $GITHUB_OUTPUT
          echo "advanced_tests_enabled=$ADVANCED_TESTS_ENABLED" >> $GITHUB_OUTPUT
          echo "total_test_count=$TOTAL_TEST_COUNT" >> $GITHUB_OUTPUT
          
          # Summary
          echo "ðŸŽ¯ Modernized E2E Test Planning Summary:"
          echo "  E2E will run: $SHOULD_RUN"
          echo "  Test suite: $TEST_SUITE"
          echo "  Advanced tests enabled: $ADVANCED_TESTS_ENABLED"
          echo "  Total test count: $TOTAL_TEST_COUNT"
          echo "  Browser matrix: $BROWSER_MATRIX"
          echo "  Is nightly: $IS_NIGHTLY"
          echo "  Using Vercel Preview Deployments (modern approach)"

  # Wait for Vercel Preview Deployment
  wait-for-preview:
    name: â³ Wait for Vercel Preview Deployment
    runs-on: ubuntu-latest
    needs: validate
    if: needs.validate.outputs.should_run_e2e == 'true' && github.event_name == 'pull_request'
    timeout-minutes: 10
    outputs:
      preview_url: ${{ steps.extract-url.outputs.preview_url }}
      
    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Install Dependencies
        run: npm ci --prefer-offline --no-audit --no-fund

      - name: â³ Wait for Vercel Deployment
        run: |
          echo "â³ Waiting for Vercel to deploy preview..."
          echo "This will take 1-3 minutes for Vercel to build and deploy"
          
          # Wait longer for Vercel to complete deployment
          sleep 90

      - name: ðŸ”— Extract Vercel Preview URL
        id: extract-url
        run: |
          echo "ðŸ”— Extracting Vercel preview URL..."
          
          # Use the modernized preview URL extraction script
          if node scripts/get-vercel-preview-url.js; then
            PREVIEW_URL=$(node scripts/get-vercel-preview-url.js 2>/dev/null | grep "PREVIEW_URL=" | cut -d= -f2)
          fi
          
          # Fallback: GitHub API approach
          if [ -z "$PREVIEW_URL" ]; then
            echo "âš ï¸ Script extraction failed, trying GitHub API fallback..."
            PREVIEW_URL=$(gh pr view ${{ github.event.number }} --json comments -q '.comments[] | select(.author.login == "vercel[bot]") | .body' | grep -oP 'https://[a-z0-9-]+\.vercel\.app' | head -1)
          fi
          
          if [ -z "$PREVIEW_URL" ]; then
            echo "âŒ No preview URL found - unable to run E2E tests"
            echo "This likely means Vercel deployment failed or is still in progress"
            exit 1
          fi
          
          echo "âœ… Preview URL extracted: $PREVIEW_URL"
          echo "preview_url=$PREVIEW_URL" >> $GITHUB_OUTPUT
          
          # Validate deployment is ready
          echo "ðŸ¥ Validating preview deployment..."
          for i in {1..20}; do
            if curl -f -s --connect-timeout 10 --max-time 30 "${PREVIEW_URL}/api/health/check" >/dev/null 2>&1; then
              echo "âœ… Preview deployment is ready for testing"
              break
            fi
            if [ $i -eq 20 ]; then
              echo "âŒ Preview deployment not responding after 5 minutes"
              exit 1
            fi
            echo "â³ Attempt $i/20: Waiting for deployment to be ready..."
            sleep 15
          done
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          GITHUB_PR_NUMBER: ${{ github.event.number }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}

  # Modern E2E testing using Vercel Preview URLs
  e2e-tests:
    name: ðŸŽ­ E2E Tests (${{ matrix.browser-name }})
    runs-on: ubuntu-latest
    needs: [validate, wait-for-preview]
    if: needs.validate.outputs.should_run_e2e == 'true'
    timeout-minutes: ${{ matrix.timeout-minutes || 15 }}
    
    strategy:
      fail-fast: false
      max-parallel: 2
      matrix:
        include: >-
          ${{
            (needs.validate.outputs.browser_matrix == 'chromium-only' && fromJson('[
              {"browser": "chromium", "browser-name": "Chrome", "timeout-minutes": 12, "retry-count": 2}
            ]')) ||
            (needs.validate.outputs.browser_matrix == 'standard' && fromJson('[
              {"browser": "chromium", "browser-name": "Chrome", "timeout-minutes": 15, "retry-count": 2},
              {"browser": "firefox", "browser-name": "Firefox", "timeout-minutes": 18, "retry-count": 3, "memory-limit": "3GB"}
            ]')) ||
            fromJson('[
              {"browser": "chromium", "browser-name": "Chrome", "timeout-minutes": 15, "retry-count": 2},
              {"browser": "firefox", "browser-name": "Firefox", "timeout-minutes": 18, "retry-count": 3, "memory-limit": "3GB"},
              {"browser": "webkit", "browser-name": "Safari", "timeout-minutes": 20, "retry-count": 3}
            ]')
          }}

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ðŸ“¦ Install Dependencies
        run: npm ci --prefer-offline --no-audit --no-fund

      - name: ðŸŽ­ Cache Playwright Browsers
        uses: actions/cache@v4
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ matrix.browser }}-${{ hashFiles('package-lock.json') }}

      - name: ðŸŽ¬ Install Playwright Browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: npx playwright install ${{ matrix.browser }} --with-deps

      - name: ðŸŽ¬ Update Browser Dependencies
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        run: npx playwright install-deps ${{ matrix.browser }}

      - name: ðŸ“ Prepare Modern Test Environment
        run: |
          # Create necessary directories
          mkdir -p test-results playwright-report
          
          # Set test environment variables
          echo "PLAYWRIGHT_BROWSER=${{ matrix.browser }}" >> $GITHUB_ENV
          echo "TEST_SUITE=${{ needs.validate.outputs.test_suite }}" >> $GITHUB_ENV
          echo "ADVANCED_TESTS_ENABLED=${{ needs.validate.outputs.advanced_tests_enabled }}" >> $GITHUB_ENV
          echo "PLAYWRIGHT_RETRIES=${{ matrix.retry-count }}" >> $GITHUB_ENV
          
          # Get the preview URL
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            PREVIEW_URL="${{ needs.wait-for-preview.outputs.preview_url }}"
          else
            # For scheduled runs or workflow dispatch, use production URL
            PREVIEW_URL="https://alocubanoboulderfest.vercel.app"
          fi
          
          echo "PLAYWRIGHT_BASE_URL=$PREVIEW_URL" >> $GITHUB_ENV
          echo "âœ… Test environment configured for ${{ matrix.browser-name }}"
          echo "ðŸŒ Target URL: $PREVIEW_URL"

      - name: ðŸ§ª Run Modern E2E Tests Against Preview Deployment
        env:
          # Memory optimization
          NODE_OPTIONS: '--max-old-space-size=3072'
          # Test credentials (for admin/auth tests)
          TEST_ADMIN_PASSWORD: ${{ secrets.TEST_ADMIN_PASSWORD || 'test-admin-password' }}
          # Advanced testing configuration
          PERFORMANCE_TESTING: ${{ needs.validate.outputs.test_suite == 'performance' }}
          ACCESSIBILITY_TESTING: ${{ needs.validate.outputs.test_suite == 'accessibility' }}
          SECURITY_TESTING: ${{ needs.validate.outputs.test_suite == 'security' }}
          ADVANCED_SCENARIOS: ${{ needs.validate.outputs.advanced_tests_enabled }}
        run: |
          echo "ðŸ§ª Running E2E tests against Vercel Preview Deployment..."
          echo "Target: $PLAYWRIGHT_BASE_URL"
          echo "Browser: ${{ matrix.browser-name }}"
          echo "Test suite: ${{ needs.validate.outputs.test_suite }}"
          echo "Advanced scenarios: ${{ needs.validate.outputs.advanced_tests_enabled }}"
          
          # Construct test command based on configuration
          TEST_CMD="npx playwright test --config=playwright-e2e-preview.config.js --project=${{ matrix.browser }}"
          
          # Add test pattern if specified
          if [ -n "${{ needs.validate.outputs.test_pattern }}" ]; then
            TEST_CMD="$TEST_CMD tests/e2e/flows/*${{ needs.validate.outputs.test_pattern }}*"
            echo "ðŸ“Š Running filtered tests: ${{ needs.validate.outputs.test_pattern }}"
          elif [ "${{ needs.validate.outputs.test_suite }}" == "performance" ]; then
            TEST_CMD="$TEST_CMD --grep=\"performance|load|gallery-browsing\""
            echo "âš¡ Running performance-focused tests"
          elif [ "${{ needs.validate.outputs.test_suite }}" == "accessibility" ]; then
            TEST_CMD="$TEST_CMD --grep=\"accessibility|mobile-registration\""
            echo "â™¿ Running accessibility compliance tests"
          elif [ "${{ needs.validate.outputs.test_suite }}" == "security" ]; then
            TEST_CMD="$TEST_CMD --grep=\"security|admin|stripe\""
            echo "ðŸ”’ Running security-focused tests"
          elif [ "${{ needs.validate.outputs.test_suite }}" == "standard" ]; then
            TEST_CMD="$TEST_CMD --grep=\"basic-navigation|cart-functionality|registration-flow|admin-auth|gallery-basic|newsletter-simple\""
            echo "ðŸ“Š Running standard test suite (core flows)"
          fi
          
          # Add timeout and retry configuration
          TEST_CMD="$TEST_CMD --timeout=120000 --retries=${{ matrix.retry-count }}"
          TEST_CMD="$TEST_CMD --reporter=list,html"
          
          echo "ðŸ“‹ Executing: $TEST_CMD"
          
          # Run tests with timeout protection
          if timeout ${{ matrix.timeout-minutes }}m $TEST_CMD; then
            echo "âœ… E2E tests completed successfully against Vercel Preview Deployment"
          else
            EXIT_CODE=$?
            echo "âŒ E2E tests failed against Vercel Preview Deployment (exit code: $EXIT_CODE)"
            exit $EXIT_CODE
          fi

      - name: ðŸ“Š Analyze Test Results
        if: always()
        run: |
          echo "ðŸ“Š Modern E2E Test Results Summary:"
          echo "  Browser: ${{ matrix.browser-name }}"
          echo "  Target: ${{ env.PLAYWRIGHT_BASE_URL }}"
          echo "  Test Suite: ${{ needs.validate.outputs.test_suite }}"
          echo "  Server Type: Vercel Preview Deployment (production-like)"
          
          if [ "${{ job.status }}" != "success" ] && [ -d "test-results" ]; then
            echo "âŒ Test failures detected, artifacts preserved"
            find test-results -name "*.png" -o -name "*.webm" | head -5 | while read -r file; do
              echo "  - $(basename "$file")"
            done
          fi

      - name: ðŸ“¤ Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-results-modern-${{ matrix.browser }}-${{ github.run_number }}
          path: |
            playwright-report/
            test-results/
          retention-days: ${{ needs.validate.outputs.is_nightly == 'true' && 14 || 7 }}

      - name: ðŸ“¸ Upload Failure Artifacts
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-failures-modern-${{ matrix.browser }}-${{ github.run_number }}
          path: |
            test-results/
            playwright-report/
          retention-days: 14

  # Results summary
  report:
    name: ðŸ“‹ Modern E2E Test Results Summary
    runs-on: ubuntu-latest
    needs: [validate, wait-for-preview, e2e-tests]
    if: always()
    timeout-minutes: 5

    steps:
      - name: ðŸ“Š Generate Modern Test Summary
        run: |
          echo "# ðŸŽ­ Modern E2E Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## Test Execution Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Validation status
          echo "- **Pre-flight Validation**: ${{ needs.validate.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }}" >> $GITHUB_STEP_SUMMARY
          
          # Preview deployment status
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            echo "- **Vercel Preview Deployment**: ${{ needs.wait-for-preview.result == 'success' && 'âœ… Ready' || 'âŒ Failed' }}" >> $GITHUB_STEP_SUMMARY
            if [ "${{ needs.wait-for-preview.result }}" == "success" ]; then
              echo "  - **Preview URL**: ${{ needs.wait-for-preview.outputs.preview_url }}" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          # E2E test status
          if [ "${{ needs.validate.outputs.should_run_e2e }}" == "true" ]; then
            echo "- **E2E Tests (Preview Deployment)**: ${{ needs.e2e-tests.result == 'success' && 'âœ… Passed' || (needs.e2e-tests.result == 'failure' && 'âŒ Failed' || 'â­ï¸ Skipped') }}" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **E2E Tests**: â­ï¸ Skipped (no relevant changes or draft PR)" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Modern approach benefits
          echo "## âš¡ Modern Testing Approach Benefits" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **ðŸŒ Production-like Environment**: Tests run against live Vercel preview deployments" >> $GITHUB_STEP_SUMMARY
          echo "- **ðŸš€ No Server Management**: Eliminates local server startup complexity and hanging issues" >> $GITHUB_STEP_SUMMARY
          echo "- **ðŸ”— Real API Integration**: Authentic serverless function execution and routing" >> $GITHUB_STEP_SUMMARY
          echo "- **âš¡ Better Reliability**: No port conflicts, resource contention, or server process management" >> $GITHUB_STEP_SUMMARY
          echo "- **ðŸŽ¯ Faster Execution**: No server startup time, immediate test execution against live URL" >> $GITHUB_STEP_SUMMARY
          echo "- **ðŸ”„ CI/CD Integration**: Native integration with Vercel's deployment workflow" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test configuration
          echo "## ðŸ“‹ Test Configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Suite**: ${{ needs.validate.outputs.test_suite }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Browser Matrix**: ${{ needs.validate.outputs.browser_matrix }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Pattern**: ${{ needs.validate.outputs.test_pattern || 'All selected tests' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Advanced Features**: ${{ needs.validate.outputs.advanced_tests_enabled }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Test Count**: ${{ needs.validate.outputs.total_test_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Is Nightly**: ${{ needs.validate.outputs.is_nightly }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Server Type**: **Vercel Preview Deployment** (modern approach)" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY

      - name: âŒ Report Test Failures
        if: needs.e2e-tests.result == 'failure'
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## âŒ Quality Gate Failures Detected" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Some E2E tests have failed against the Vercel Preview Deployment. Please review:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ” **Debugging Steps**:" >> $GITHUB_STEP_SUMMARY
          echo "1. **Check test artifacts** for detailed error logs and screenshots" >> $GITHUB_STEP_SUMMARY  
          echo "2. **Visit the preview URL** to manually reproduce issues" >> $GITHUB_STEP_SUMMARY
          echo "3. **Run locally**: Use the same preview URL with local Playwright" >> $GITHUB_STEP_SUMMARY
          echo "4. **Check browser compatibility** for specific browser failures" >> $GITHUB_STEP_SUMMARY
          echo "5. **Verify deployment**: Ensure preview deployment is fully functional" >> $GITHUB_STEP_SUMMARY
          
          exit 1

      - name: âœ… Report Test Success
        if: |
          always() && 
          needs.validate.result == 'success' && 
          (needs.e2e-tests.result == 'success' || needs.validate.outputs.should_run_e2e != 'true') &&
          (needs.wait-for-preview.result == 'success' || needs.wait-for-preview.result == 'skipped')
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## âœ… All Quality Gates Passed!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸŽ‰ **Congratulations!** Your changes have passed all modern E2E quality gates." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸš€ **Modern Testing Success**" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Production-like validation** against live Vercel Preview Deployment" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Cross-browser compatibility** confirmed across selected browser matrix" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Real API integration** tested with authentic serverless behavior" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Enhanced reliability** with modern testing approach" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Zero infrastructure complexity** - no local servers or port management" >> $GITHUB_STEP_SUMMARY