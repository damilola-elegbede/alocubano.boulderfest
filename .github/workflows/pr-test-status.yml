name: 💬 PR Test Status Comments

on:
  workflow_run:
    workflows: 
      - "Main CI Pipeline"
      - "Enhanced Main CI Pipeline"
    types: 
      - completed
    branches:
      - main
      - develop
      - feature/**

concurrency:
  group: pr-test-status-${{ github.event.workflow_run.head_branch }}
  cancel-in-progress: true

jobs:
  post-test-comment:
    name: 💬 Update PR Test Status
    runs-on: ubuntu-latest
    if: github.event.workflow_run.event == 'pull_request'
    timeout-minutes: 10

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: 📦 Install dependencies
        run: npm install glob

      - name: 📊 Get Workflow Run Details
        id: workflow-details
        uses: actions/github-script@v7
        with:
          script: |
            const workflowRun = context.payload.workflow_run;
            
            core.setOutput('run-id', workflowRun.id);
            core.setOutput('conclusion', workflowRun.conclusion);
            core.setOutput('head-sha', workflowRun.head_sha);
            core.setOutput('head-branch', workflowRun.head_branch);
            core.setOutput('run-attempt', workflowRun.run_attempt);
            core.setOutput('run-started-at', workflowRun.run_started_at);
            core.setOutput('updated-at', workflowRun.updated_at);
            
            // Calculate total execution time
            const startTime = new Date(workflowRun.run_started_at);
            const endTime = new Date(workflowRun.updated_at);
            const totalSeconds = Math.floor((endTime - startTime) / 1000);
            core.setOutput('total-time', totalSeconds);

      - name: 📋 Find Associated PR
        id: find-pr
        uses: actions/github-script@v7
        with:
          script: |
            const { data: pulls } = await github.rest.pulls.list({
              owner: context.repo.owner,
              repo: context.repo.repo,
              head: `${context.repo.owner}:${{ steps.workflow-details.outputs.head-branch }}`,
              state: 'open'
            });
            
            if (pulls.length > 0) {
              core.setOutput('pr-number', pulls[0].number);
              core.setOutput('has-pr', 'true');
              console.log(`Found PR #${pulls[0].number} for branch ${{ steps.workflow-details.outputs.head-branch }}`);
            } else {
              core.setOutput('has-pr', 'false');
              console.log('No open PR found for this branch');
            }

      - name: 📥 Download Workflow Artifacts
        if: steps.find-pr.outputs.has-pr == 'true'
        uses: actions/download-artifact@v4
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ steps.workflow-details.outputs.run-id }}
          path: artifacts/
        continue-on-error: true

      - name: 📊 Collect Test Results
        if: steps.find-pr.outputs.has-pr == 'true'
        id: collect-results
        run: |
          echo "🔍 Collecting test results from artifacts..."
          
          # Initialize default results
          UNIT_RESULTS='{"status":"skipped","test_count":0,"passed_count":0,"failed_count":0,"execution_time":0,"coverage":"0"}'
          E2E_RESULTS='[]'
          PERFORMANCE_RESULTS='{"status":"skipped"}'
          SECURITY_RESULTS='{"status":"skipped","vulnerabilities":0,"critical_vulnerabilities":0}'
          BUILD_STATUS="unknown"
          
          # Look for unit test results
          if [ -f "artifacts/unit-test-results-*/test-results.json" ]; then
            echo "📊 Processing unit test results..."
            UNIT_FILE=$(find artifacts -name "test-results.json" -type f | head -1)
            if [ -f "$UNIT_FILE" ]; then
              TOTAL=$(jq -r '.numTotalTests // 0' "$UNIT_FILE")
              PASSED=$(jq -r '.numPassedTests // 0' "$UNIT_FILE")
              FAILED=$(jq -r '.numFailedTests // 0' "$UNIT_FILE")
              SKIPPED=$(jq -r '.numPendingTests // 0' "$UNIT_FILE")
              STATUS=$([ "$FAILED" -gt 0 ] && echo "failure" || echo "success")
              
              # Look for coverage
              COVERAGE="0"
              COVERAGE_FILE=$(find artifacts -name "coverage-summary.json" -type f | head -1)
              if [ -f "$COVERAGE_FILE" ]; then
                COVERAGE=$(jq -r '.total.lines.pct // 0' "$COVERAGE_FILE" 2>/dev/null || echo "0")
              fi
              
              UNIT_RESULTS="{\"status\":\"$STATUS\",\"test_count\":$TOTAL,\"passed_count\":$PASSED,\"failed_count\":$FAILED,\"skipped_count\":$SKIPPED,\"execution_time\":30,\"coverage\":\"$COVERAGE\"}"
            fi
          fi
          
          # Look for E2E test results  
          E2E_RESULTS_ARRAY=""
          if find artifacts -name "e2e-*-results.json" -type f | head -1 >/dev/null 2>&1; then
            echo "🎭 Processing E2E test results..."
            
            for file in artifacts/*/e2e-*-results.json; do
              if [ -f "$file" ]; then
                BROWSER=$(basename "$file" | sed 's/e2e-//g' | sed 's/-results.json//g')
                
                # Extract basic metrics from Playwright JSON
                TOTAL_SPECS=$(jq '[.suites[]?.specs[]?] | length' "$file" 2>/dev/null || echo "0")
                PASSED_SPECS=$(jq '[.suites[]?.specs[]? | select(.ok == true)] | length' "$file" 2>/dev/null || echo "0")
                FAILED_SPECS=$(jq '[.suites[]?.specs[]? | select(.ok == false)] | length' "$file" 2>/dev/null || echo "0")
                
                STATUS=$([ "$FAILED_SPECS" -gt 0 ] && echo "failure" || echo "success")
                
                E2E_RESULT="{\"browser\":\"$BROWSER\",\"status\":\"$STATUS\",\"test_count\":$TOTAL_SPECS,\"passed_count\":$PASSED_SPECS,\"failed_count\":$FAILED_SPECS,\"execution_time\":90,\"flaky_tests\":[]}"
                
                if [ -z "$E2E_RESULTS_ARRAY" ]; then
                  E2E_RESULTS_ARRAY="$E2E_RESULT"
                else
                  E2E_RESULTS_ARRAY="$E2E_RESULTS_ARRAY,$E2E_RESULT"
                fi
              fi
            done
            
            if [ -n "$E2E_RESULTS_ARRAY" ]; then
              E2E_RESULTS="[$E2E_RESULTS_ARRAY]"
            fi
          fi
          
          # Look for performance results
          if [ -f "artifacts/performance-results-*/performance-results.json" ]; then
            echo "⚡ Processing performance results..."
            PERF_FILE=$(find artifacts -name "performance-results.json" -type f | head -1)
            if [ -f "$PERF_FILE" ]; then
              PERFORMANCE_RESULTS="{\"status\":\"success\",\"execution_time\":60,\"metrics\":$(cat "$PERF_FILE")}"
            fi
          fi
          
          # Look for security results
          if [ -f "artifacts/*/audit-output.log" ]; then
            echo "🔒 Processing security results..."
            AUDIT_FILE=$(find artifacts -name "audit-output.log" -type f | head -1)
            if [ -f "$AUDIT_FILE" ]; then
              VULNS=$(grep -c "vulnerabilities" "$AUDIT_FILE" 2>/dev/null || echo "0")
              CRITICAL=$(grep -c "critical" "$AUDIT_FILE" 2>/dev/null || echo "0")
              STATUS=$([ "$CRITICAL" -gt 0 ] && echo "failure" || ([ "$VULNS" -gt 0 ] && echo "warning" || echo "success"))
              SECURITY_RESULTS="{\"status\":\"$STATUS\",\"vulnerabilities\":$VULNS,\"critical_vulnerabilities\":$CRITICAL}"
            fi
          fi
          
          # Determine build status from workflow conclusion
          case "${{ steps.workflow-details.outputs.conclusion }}" in
            "success") BUILD_STATUS="success" ;;
            "failure") BUILD_STATUS="failure" ;;
            *) BUILD_STATUS="unknown" ;;
          esac
          
          # Set outputs for next step
          echo "unit-results=$(echo "$UNIT_RESULTS" | jq -c .)" >> $GITHUB_OUTPUT
          echo "e2e-results=$(echo "$E2E_RESULTS" | jq -c .)" >> $GITHUB_OUTPUT
          echo "performance-results=$(echo "$PERFORMANCE_RESULTS" | jq -c .)" >> $GITHUB_OUTPUT
          echo "security-results=$(echo "$SECURITY_RESULTS" | jq -c .)" >> $GITHUB_OUTPUT
          echo "build-status=$BUILD_STATUS" >> $GITHUB_OUTPUT
          
          echo "✅ Test results collected"

      - name: 💬 Generate and Post Test Comment
        if: steps.find-pr.outputs.has-pr == 'true'
        uses: actions/github-script@v7
        env:
          UNIT_RESULTS: ${{ steps.collect-results.outputs.unit-results }}
          E2E_RESULTS: ${{ steps.collect-results.outputs.e2e-results }}
          PERFORMANCE_RESULTS: ${{ steps.collect-results.outputs.performance-results }}
          SECURITY_RESULTS: ${{ steps.collect-results.outputs.security-results }}
          BUILD_STATUS: ${{ steps.collect-results.outputs.build-status }}
          WORKFLOW_CONCLUSION: ${{ steps.workflow-details.outputs.conclusion }}
          TOTAL_TIME: ${{ steps.workflow-details.outputs.total-time }}
          RUN_ID: ${{ steps.workflow-details.outputs.run-id }}
          HEAD_SHA: ${{ steps.workflow-details.outputs.head-sha }}
          HEAD_BRANCH: ${{ steps.workflow-details.outputs.head-branch }}
        with:
          script: |
            const pr_number = ${{ steps.find-pr.outputs.pr-number }};
            
            // Parse results
            const unitResults = JSON.parse(process.env.UNIT_RESULTS || '{}');
            const e2eResults = JSON.parse(process.env.E2E_RESULTS || '[]');
            const performanceResults = JSON.parse(process.env.PERFORMANCE_RESULTS || '{}');
            const securityResults = JSON.parse(process.env.SECURITY_RESULTS || '{}');
            const buildStatus = process.env.BUILD_STATUS;
            const workflowConclusion = process.env.WORKFLOW_CONCLUSION;
            const totalTime = parseInt(process.env.TOTAL_TIME || '0');
            const runId = process.env.RUN_ID;
            const headSha = process.env.HEAD_SHA;
            const headBranch = process.env.HEAD_BRANCH;
            
            // Determine overall status
            let overallStatus = 'success';
            if (workflowConclusion === 'failure' || buildStatus === 'failure' || unitResults.status === 'failure') {
              overallStatus = 'failure';
            } else if (e2eResults.some(r => r.status === 'failure')) {
              overallStatus = 'failure';
            } else if (performanceResults.status === 'failure' || securityResults.status === 'failure') {
              overallStatus = 'warning';
            }
            
            // Status emojis
            const getStatusEmoji = (status) => {
              switch (status) {
                case 'success': return '✅';
                case 'failure': return '❌';
                case 'warning': return '⚠️';
                default: return '⏭️';
              }
            };
            
            const formatDuration = (seconds) => {
              if (seconds < 60) return `${seconds}s`;
              if (seconds < 3600) return `${Math.floor(seconds/60)}m ${seconds%60}s`;
              return `${Math.floor(seconds/3600)}h ${Math.floor((seconds%3600)/60)}m ${seconds%60}s`;
            };
            
            // Build comment
            const overallEmoji = getStatusEmoji(overallStatus);
            const unitEmoji = getStatusEmoji(unitResults.status || 'skipped');
            const buildEmoji = getStatusEmoji(buildStatus);
            
            let comment = `## ${overallEmoji} Test Results Summary
            
**Branch:** \`${headBranch}\` | **Commit:** \`${headSha.substring(0, 8)}\` | **Total Time:** ${formatDuration(totalTime)}

### 🧪 Test Status Overview

| Test Suite | Status | Details |
|------------|--------|---------|`;
            
            // Unit Tests
            if (unitResults.status && unitResults.status !== 'skipped') {
              comment += `\n| **Unit Tests** | ${unitEmoji} | ${unitResults.passed_count}/${unitResults.test_count} passed • ${formatDuration(unitResults.execution_time || 0)} • ${unitResults.coverage || 0}% coverage |`;
            }
            
            // E2E Tests
            if (e2eResults.length > 0) {
              const totalE2eTests = e2eResults.reduce((sum, r) => sum + (r.test_count || 0), 0);
              const totalE2ePassed = e2eResults.reduce((sum, r) => sum + (r.passed_count || 0), 0);
              const e2eStatus = e2eResults.some(r => r.status === 'failure') ? 'failure' : 'success';
              const e2eEmoji = getStatusEmoji(e2eStatus);
              const maxE2eTime = Math.max(...e2eResults.map(r => r.execution_time || 0));
              
              comment += `\n| **E2E Tests** | ${e2eEmoji} | ${totalE2ePassed}/${totalE2eTests} passed • ${e2eResults.length} browsers • ${formatDuration(maxE2eTime)} max |`;
            }
            
            // Performance
            if (performanceResults.status && performanceResults.status !== 'skipped') {
              const perfEmoji = getStatusEmoji(performanceResults.status);
              comment += `\n| **Performance** | ${perfEmoji} | Load testing completed • ${formatDuration(performanceResults.execution_time || 0)} |`;
            }
            
            // Security
            if (securityResults.status && securityResults.status !== 'skipped') {
              const secEmoji = getStatusEmoji(securityResults.status);
              comment += `\n| **Security Scan** | ${secEmoji} | ${securityResults.vulnerabilities || 0} vulnerabilities found |`;
            }
            
            // Build
            comment += `\n| **Build** | ${buildEmoji} | ${buildStatus === 'success' ? 'Deployment ready' : 'Build failed'} |`;
            
            // Detailed results
            comment += `\n\n<details>\n<summary>📊 Detailed Test Results</summary>\n\n`;
            
            // Unit details
            if (unitResults.status && unitResults.status !== 'skipped') {
              comment += `#### 🧪 Unit Tests\n\n- **Total Tests:** ${unitResults.test_count}\n- **Passed:** ${unitResults.passed_count}\n- **Failed:** ${unitResults.failed_count}\n- **Coverage:** ${unitResults.coverage}%\n\n`;
            }
            
            // E2E details
            if (e2eResults.length > 0) {
              comment += `#### 🎭 E2E Tests\n\n`;
              for (const result of e2eResults) {
                const statusIcon = getStatusEmoji(result.status);
                comment += `**${result.browser}** ${statusIcon}\n- Tests: ${result.passed_count}/${result.test_count} passed\n- Time: ${formatDuration(result.execution_time)}\n\n`;
              }
            }
            
            // Performance details
            if (performanceResults.status && performanceResults.status !== 'skipped') {
              comment += `#### ⚡ Performance Tests\n\n- **Status:** ${performanceResults.status === 'success' ? 'All benchmarks passed' : 'Performance issues detected'}\n\n`;
            }
            
            // Security details
            if (securityResults.status && securityResults.status !== 'skipped') {
              comment += `#### 🔒 Security Scan\n\n- **Vulnerabilities:** ${securityResults.vulnerabilities}\n- **Critical:** ${securityResults.critical_vulnerabilities}\n\n`;
            }
            
            comment += `</details>\n\n`;
            
            // Failure details
            if (overallStatus === 'failure') {
              comment += `<details>\n<summary>❌ Failure Analysis</summary>\n\n`;
              
              if (unitResults.status === 'failure') {
                comment += `#### Unit Test Failures\n- ${unitResults.failed_count} tests failed\n- Check unit test logs for detailed error messages\n\n`;
              }
              
              const failedE2e = e2eResults.filter(r => r.status === 'failure');
              if (failedE2e.length > 0) {
                comment += `#### E2E Test Failures\n- Failed browsers: ${failedE2e.map(r => r.browser).join(', ')}\n- Check browser-specific artifacts for screenshots and videos\n\n`;
              }
              
              if (buildStatus === 'failure') {
                comment += `#### Build Failures\n- Check build logs for compilation errors\n- Verify all dependencies are properly installed\n\n`;
              }
              
              comment += `</details>\n\n`;
            }
            
            // Footer
            comment += `---\n\n📋 [Full CI Results](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${runId}) | 🔄 **Last updated:** ${new Date().toISOString().replace('T', ' ').substr(0, 16)} UTC\n\n*This comment will be automatically updated on new commits*`;
            
            // Look for existing comment to update
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: pr_number,
            });
            
            const existingComment = comments.find(c => 
              c.user?.type === 'Bot' && 
              (c.body.includes('Test Results Summary') || c.body.includes('📋 [Full CI Results]'))
            );
            
            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
              console.log(`Updated existing comment: ${existingComment.html_url}`);
            } else {
              const { data: newComment } = await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: pr_number,
                body: comment
              });
              console.log(`Created new comment: ${newComment.html_url}`);
            }

      - name: 📊 Summary Report
        if: always()
        run: |
          echo "========================================"
          echo "💬 PR Test Status Comment Summary"
          echo "========================================"
          echo "Workflow Run: ${{ steps.workflow-details.outputs.run-id }}"
          echo "Conclusion: ${{ steps.workflow-details.outputs.conclusion }}"
          echo "Branch: ${{ steps.workflow-details.outputs.head-branch }}"
          echo "PR Found: ${{ steps.find-pr.outputs.has-pr }}"
          echo "PR Number: ${{ steps.find-pr.outputs.pr-number }}"
          echo "Total Time: ${{ steps.workflow-details.outputs.total-time }}s"
          echo "========================================"