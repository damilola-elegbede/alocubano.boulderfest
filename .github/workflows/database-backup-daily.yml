name: "ğŸ’¾ Daily Database Backup"

on:
  schedule:
    # Daily at 3 AM UTC (8 PM Mountain Time previous day)
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      database:
        description: 'Database to backup (prod, dev, or both)'
        required: false
        default: 'both'
        type: choice
        options:
          - both
          - prod
          - dev

permissions:
  contents: read

env:
  NODE_VERSION: "20.19.5"

jobs:
  backup-production:
    name: "ğŸ’¾ Backup Production"
    runs-on: ubuntu-latest
    timeout-minutes: 15

    # Run on schedule, manual trigger for prod/both, or push/PR events (for testing)
    if: |
      github.event_name == 'schedule' ||
      github.event_name == 'push' ||
      github.event_name == 'pull_request' ||
      github.event.inputs.database == 'both' ||
      github.event.inputs.database == 'prod'

    steps:
      - name: "ğŸ“¥ Checkout Code"
        uses: actions/checkout@v4

      - name: "ğŸ”§ Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: "ğŸ“¦ Install Dependencies"
        run: |
          echo "ğŸ“¦ Installing @vercel/blob SDK..."
          npm install @vercel/blob --no-save --no-audit

      - name: "ğŸ”§ Install Turso CLI"
        run: |
          echo "ğŸ”§ Installing Turso CLI..."
          curl -sSfL https://get.tur.so/install.sh | bash

          # Verify installation
          if [ ! -f "$HOME/.turso/turso" ]; then
            echo "âŒ Turso CLI installation failed - binary not found"
            exit 1
          fi

          echo "âœ… Turso CLI installed: $(ls -lh $HOME/.turso/turso)"

          # Add to PATH for subsequent steps (correct directory)
          echo "$HOME/.turso" >> $GITHUB_PATH

      - name: "ğŸ” Verify Turso API Token"
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
        run: |
          echo "ğŸ” Verifying Turso API token..."

          # Check if token is set
          if [ -z "$TURSO_API_TOKEN" ]; then
            echo "âŒ TURSO_API_TOKEN secret is not set"
            echo ""
            echo "ğŸ“ Fix: Go to GitHub Settings â†’ Secrets â†’ Actions â†’ New secret"
            echo "   Name: TURSO_API_TOKEN"
            echo "   Value: Run 'turso auth token' to get your platform API token"
            echo ""
            echo "âš ï¸  Note: TURSO_API_TOKEN (platform token) is different from"
            echo "   TURSO_AUTH_TOKEN (database connection token)"
            exit 1
          fi

          # Verify token format (JWT should start with 'eyJ')
          if [[ ! "$TURSO_API_TOKEN" =~ ^eyJ ]]; then
            echo "âš ï¸  Warning: Token doesn't appear to be a valid JWT (should start with 'eyJ')"
          fi

          echo "âœ… TURSO_API_TOKEN is configured"

      - name: "ğŸ” Verify Database Access"
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
          DB_NAME: ${{ vars.TURSO_PROD_DB_NAME }}
        run: |
          echo "ğŸ” Verifying production database access..."

          if turso db show "$DB_NAME" > /dev/null 2>&1; then
            echo "âœ… Can access production database"

            # Verify we can query the database
            TABLE_COUNT=$(turso db shell "$DB_NAME" "SELECT COUNT(*) as count FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'" | tail -n 1 | tr -d ' ')
            echo "ğŸ“Š Tables in database: $TABLE_COUNT"
          else
            echo "âŒ Cannot access production database"
            exit 1
          fi

          echo "âœ… Database access verification complete"

      - name: "ğŸ’¾ Create Database Backup"
        id: backup
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
          DB_NAME: ${{ vars.TURSO_PROD_DB_NAME }}
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ’¾ Creating Production Database Backup"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Database: $DB_NAME"
          echo "ğŸ“… Date: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

          # Generate backup filenames with timestamp
          TIMESTAMP=$(date -u '+%Y-%m-%d_%H-%M-%S')
          DB_FILE="backup-prod-${TIMESTAMP}.db"
          BACKUP_FILE="backup-prod-${TIMESTAMP}.sql"
          COMPRESSED_FILE="${BACKUP_FILE}.gz"

          # Export database to SQLite format (reliable for CI/CD)
          echo "ğŸ“¤ Exporting database to SQLite format..."
          turso db export "$DB_NAME" --output-file "$DB_FILE" --overwrite

          # Check if export succeeded
          if [ ! -s "$DB_FILE" ]; then
            echo "âŒ Database export failed or is empty"
            exit 1
          fi

          SQLITE_SIZE=$(stat -f%z "$DB_FILE" 2>/dev/null || stat -c%s "$DB_FILE")
          echo "âœ… Database exported: $(numfmt --to=iec-i --suffix=B $SQLITE_SIZE || echo ${SQLITE_SIZE}B)"

          # Convert SQLite to SQL format for compatibility
          echo "ğŸ”„ Converting to SQL format..."
          sqlite3 "$DB_FILE" .dump > "$BACKUP_FILE"

          # Clean up SQLite files
          rm -f "$DB_FILE" "${DB_FILE}-wal"

          # Verify SQL dump
          if [ ! -s "$BACKUP_FILE" ]; then
            echo "âŒ SQL conversion failed or is empty"
            exit 1
          fi

          ORIGINAL_SIZE=$(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE")
          echo "âœ… SQL dump created: $(numfmt --to=iec-i --suffix=B $ORIGINAL_SIZE || echo ${ORIGINAL_SIZE}B)"

          # Compress backup
          echo "ğŸ—œï¸  Compressing backup..."
          gzip -9 "$BACKUP_FILE"

          COMPRESSED_SIZE=$(stat -f%z "$COMPRESSED_FILE" 2>/dev/null || stat -c%s "$COMPRESSED_FILE")
          COMPRESSION_RATIO=$(awk "BEGIN {printf \"%.1f\", (1 - $COMPRESSED_SIZE / $ORIGINAL_SIZE) * 100}")

          echo "âœ… Backup compressed: $(numfmt --to=iec-i --suffix=B $COMPRESSED_SIZE || echo ${COMPRESSED_SIZE}B) (${COMPRESSION_RATIO}% reduction)"

          # Export variables for next steps
          echo "backup_file=$COMPRESSED_FILE" >> $GITHUB_OUTPUT
          echo "original_size=$ORIGINAL_SIZE" >> $GITHUB_OUTPUT
          echo "compressed_size=$COMPRESSED_SIZE" >> $GITHUB_OUTPUT
          echo "compression_ratio=$COMPRESSION_RATIO" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: "â˜ï¸  Upload to Vercel Blob Storage"
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
        run: |
          echo "â˜ï¸  Uploading backup to Vercel Blob Storage..."
          node scripts/upload-backup-to-blob.js \
            "${{ steps.backup.outputs.backup_file }}" \
            "prod"

      - name: "ğŸ§¹ Cleanup Old Backups"
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
        run: |
          echo "ğŸ§¹ Cleaning up backups older than 30 days..."
          node scripts/cleanup-old-backups.js --retention-days 30

      - name: "ğŸ“¤ Upload Backup Artifact"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-prod-${{ steps.backup.outputs.timestamp }}
          path: ${{ steps.backup.outputs.backup_file }}
          retention-days: 7
          compression-level: 0  # Already compressed with gzip

      - name: "ğŸ“Š Backup Summary"
        if: always()
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Backup Summary - Production"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… Status: ${{ job.status }}"
          echo "ğŸ“¦ Original Size: ${{ steps.backup.outputs.original_size }} bytes"
          echo "ğŸ—œï¸  Compressed Size: ${{ steps.backup.outputs.compressed_size }} bytes"
          echo "ğŸ“‰ Compression: ${{ steps.backup.outputs.compression_ratio }}%"
          echo "ğŸ“… Timestamp: ${{ steps.backup.outputs.timestamp }}"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  backup-development:
    name: "ğŸ’¾ Backup Development"
    runs-on: ubuntu-latest
    timeout-minutes: 15

    # Run on schedule, manual trigger for dev/both, or push/PR events (for testing)
    if: |
      github.event_name == 'schedule' ||
      github.event_name == 'push' ||
      github.event_name == 'pull_request' ||
      github.event.inputs.database == 'both' ||
      github.event.inputs.database == 'dev'

    steps:
      - name: "ğŸ“¥ Checkout Code"
        uses: actions/checkout@v4

      - name: "ğŸ”§ Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: "ğŸ“¦ Install Dependencies"
        run: |
          echo "ğŸ“¦ Installing @vercel/blob SDK..."
          npm install @vercel/blob --no-save --no-audit

      - name: "ğŸ”§ Install Turso CLI"
        run: |
          echo "ğŸ”§ Installing Turso CLI..."
          curl -sSfL https://get.tur.so/install.sh | bash

          # Verify installation
          if [ ! -f "$HOME/.turso/turso" ]; then
            echo "âŒ Turso CLI installation failed - binary not found"
            exit 1
          fi

          echo "âœ… Turso CLI installed: $(ls -lh $HOME/.turso/turso)"

          # Add to PATH for subsequent steps (correct directory)
          echo "$HOME/.turso" >> $GITHUB_PATH

      - name: "ğŸ” Verify Turso API Token"
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
        run: |
          echo "ğŸ” Verifying Turso API token..."

          # Check if token is set
          if [ -z "$TURSO_API_TOKEN" ]; then
            echo "âŒ TURSO_API_TOKEN secret is not set"
            echo ""
            echo "ğŸ“ Fix: Go to GitHub Settings â†’ Secrets â†’ Actions â†’ New secret"
            echo "   Name: TURSO_API_TOKEN"
            echo "   Value: Run 'turso auth token' to get your platform API token"
            echo ""
            echo "âš ï¸  Note: TURSO_API_TOKEN (platform token) is different from"
            echo "   TURSO_AUTH_TOKEN (database connection token)"
            exit 1
          fi

          # Verify token format (JWT should start with 'eyJ')
          if [[ ! "$TURSO_API_TOKEN" =~ ^eyJ ]]; then
            echo "âš ï¸  Warning: Token doesn't appear to be a valid JWT (should start with 'eyJ')"
          fi

          echo "âœ… TURSO_API_TOKEN is configured"

      - name: "ğŸ” Verify Database Access"
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
          DB_NAME: ${{ vars.TURSO_DEV_DB_NAME }}
        run: |
          echo "ğŸ” Verifying development database access..."

          if turso db show "$DB_NAME" > /dev/null 2>&1; then
            echo "âœ… Can access development database"

            # Verify we can query the database
            TABLE_COUNT=$(turso db shell "$DB_NAME" "SELECT COUNT(*) as count FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'" | tail -n 1 | tr -d ' ')
            echo "ğŸ“Š Tables in database: $TABLE_COUNT"
          else
            echo "âŒ Cannot access development database"
            exit 1
          fi

          echo "âœ… Database access verification complete"

      - name: "ğŸ’¾ Create Database Backup"
        id: backup
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
          DB_NAME: ${{ vars.TURSO_DEV_DB_NAME }}
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ’¾ Creating Development Database Backup"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Database: $DB_NAME"
          echo "ğŸ“… Date: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

          # Generate backup filenames with timestamp
          TIMESTAMP=$(date -u '+%Y-%m-%d_%H-%M-%S')
          DB_FILE="backup-dev-${TIMESTAMP}.db"
          BACKUP_FILE="backup-dev-${TIMESTAMP}.sql"
          COMPRESSED_FILE="${BACKUP_FILE}.gz"

          # Export database to SQLite format (reliable for CI/CD)
          echo "ğŸ“¤ Exporting database to SQLite format..."
          turso db export "$DB_NAME" --output-file "$DB_FILE" --overwrite

          # Check if export succeeded
          if [ ! -s "$DB_FILE" ]; then
            echo "âŒ Database export failed or is empty"
            exit 1
          fi

          SQLITE_SIZE=$(stat -f%z "$DB_FILE" 2>/dev/null || stat -c%s "$DB_FILE")
          echo "âœ… Database exported: $(numfmt --to=iec-i --suffix=B $SQLITE_SIZE || echo ${SQLITE_SIZE}B)"

          # Convert SQLite to SQL format for compatibility
          echo "ğŸ”„ Converting to SQL format..."
          sqlite3 "$DB_FILE" .dump > "$BACKUP_FILE"

          # Clean up SQLite files
          rm -f "$DB_FILE" "${DB_FILE}-wal"

          # Verify SQL dump
          if [ ! -s "$BACKUP_FILE" ]; then
            echo "âŒ SQL conversion failed or is empty"
            exit 1
          fi

          ORIGINAL_SIZE=$(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE")
          echo "âœ… SQL dump created: $(numfmt --to=iec-i --suffix=B $ORIGINAL_SIZE || echo ${ORIGINAL_SIZE}B)"

          # Compress backup
          echo "ğŸ—œï¸  Compressing backup..."
          gzip -9 "$BACKUP_FILE"

          COMPRESSED_SIZE=$(stat -f%z "$COMPRESSED_FILE" 2>/dev/null || stat -c%s "$COMPRESSED_FILE")
          COMPRESSION_RATIO=$(awk "BEGIN {printf \"%.1f\", (1 - $COMPRESSED_SIZE / $ORIGINAL_SIZE) * 100}")

          echo "âœ… Backup compressed: $(numfmt --to=iec-i --suffix=B $COMPRESSED_SIZE || echo ${COMPRESSED_SIZE}B) (${COMPRESSION_RATIO}% reduction)"

          # Export variables for next steps
          echo "backup_file=$COMPRESSED_FILE" >> $GITHUB_OUTPUT
          echo "original_size=$ORIGINAL_SIZE" >> $GITHUB_OUTPUT
          echo "compressed_size=$COMPRESSED_SIZE" >> $GITHUB_OUTPUT
          echo "compression_ratio=$COMPRESSION_RATIO" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: "â˜ï¸  Upload to Vercel Blob Storage"
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
        run: |
          echo "â˜ï¸  Uploading backup to Vercel Blob Storage..."
          node scripts/upload-backup-to-blob.js \
            "${{ steps.backup.outputs.backup_file }}" \
            "dev"

      - name: "ğŸ§¹ Cleanup Old Backups"
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
        run: |
          echo "ğŸ§¹ Cleaning up backups older than 30 days..."
          node scripts/cleanup-old-backups.js --retention-days 30

      - name: "ğŸ“¤ Upload Backup Artifact"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-dev-${{ steps.backup.outputs.timestamp }}
          path: ${{ steps.backup.outputs.backup_file }}
          retention-days: 7
          compression-level: 0  # Already compressed with gzip

      - name: "ğŸ“Š Backup Summary"
        if: always()
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Backup Summary - Development"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… Status: ${{ job.status }}"
          echo "ğŸ“¦ Original Size: ${{ steps.backup.outputs.original_size }} bytes"
          echo "ğŸ—œï¸  Compressed Size: ${{ steps.backup.outputs.compressed_size }} bytes"
          echo "ğŸ“‰ Compression: ${{ steps.backup.outputs.compression_ratio }}%"
          echo "ğŸ“… Timestamp: ${{ steps.backup.outputs.timestamp }}"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  notify:
    name: "ğŸ“§ Notify on Failure"
    runs-on: ubuntu-latest
    needs: [backup-production, backup-development]
    if: always() && (needs.backup-production.result == 'failure' || needs.backup-development.result == 'failure')

    steps:
      - name: "ğŸ“§ Send Failure Notification"
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âŒ BACKUP FAILURE NOTIFICATION"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "â° Time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "ğŸ”— Workflow: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
          echo "âš ï¸  Daily database backup failed!"
          echo "   Please check the workflow logs and investigate immediately."
          echo ""
          echo "ğŸ” Common Issues:"
          echo "   - Turso authentication failure (check TURSO_AUTH_TOKEN)"
          echo "   - Vercel Blob upload failure (check BLOB_READ_WRITE_TOKEN)"
          echo "   - Database connectivity issues"
          echo "   - Insufficient storage quota"
          echo ""
          echo "ğŸ“š See docs/DISASTER_RECOVERY.md for troubleshooting guidance"
