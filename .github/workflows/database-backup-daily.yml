name: "💾 Daily Database Backup"

on:
  schedule:
    # Daily at 3 AM UTC (8 PM Mountain Time previous day)
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      database:
        description: 'Database to backup (prod, dev, or both)'
        required: false
        default: 'both'
        type: choice
        options:
          - both
          - prod
          - dev

permissions:
  contents: read

env:
  NODE_VERSION: "20.19.5"

jobs:
  backup-production:
    name: "💾 Backup Production"
    runs-on: ubuntu-latest
    timeout-minutes: 15

    # Run on schedule, manual trigger for prod/both, or push/PR events (for testing)
    if: |
      github.event_name == 'schedule' ||
      github.event_name == 'push' ||
      github.event_name == 'pull_request' ||
      github.event.inputs.database == 'both' ||
      github.event.inputs.database == 'prod'

    steps:
      - name: "📥 Checkout Code"
        uses: actions/checkout@v4

      - name: "🔧 Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: "📦 Install Dependencies"
        run: |
          echo "📦 Installing @vercel/blob SDK..."
          npm install @vercel/blob --no-save --no-audit

      - name: "🔧 Install Turso CLI"
        run: |
          echo "🔧 Installing Turso CLI..."
          curl -sSfL https://get.tur.so/install.sh | bash

          # Verify installation
          if [ ! -f "$HOME/.turso/turso" ]; then
            echo "❌ Turso CLI installation failed - binary not found"
            exit 1
          fi

          echo "✅ Turso CLI installed: $(ls -lh $HOME/.turso/turso)"

          # Add to PATH for subsequent steps (correct directory)
          echo "$HOME/.turso" >> $GITHUB_PATH

      - name: "🔐 Verify Turso API Token"
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
        run: |
          echo "🔐 Verifying Turso API token..."

          # Check if token is set
          if [ -z "$TURSO_API_TOKEN" ]; then
            echo "❌ TURSO_API_TOKEN secret is not set"
            echo ""
            echo "📝 Fix: Go to GitHub Settings → Secrets → Actions → New secret"
            echo "   Name: TURSO_API_TOKEN"
            echo "   Value: Run 'turso auth token' to get your platform API token"
            echo ""
            echo "⚠️  Note: TURSO_API_TOKEN (platform token) is different from"
            echo "   TURSO_AUTH_TOKEN (database connection token)"
            exit 1
          fi

          # Verify token format (JWT should start with 'eyJ')
          if [[ ! "$TURSO_API_TOKEN" =~ ^eyJ ]]; then
            echo "⚠️  Warning: Token doesn't appear to be a valid JWT (should start with 'eyJ')"
          fi

          echo "✅ TURSO_API_TOKEN is configured"

      - name: "🔍 Verify Database Access"
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
          DB_NAME: ${{ vars.TURSO_PROD_DB_NAME }}
        run: |
          echo "🔍 Verifying production database access..."

          if turso db show "$DB_NAME" > /dev/null 2>&1; then
            echo "✅ Can access production database"

            # Verify we can query the database
            TABLE_COUNT=$(turso db shell "$DB_NAME" "SELECT COUNT(*) as count FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'" | tail -n 1 | tr -d ' ')
            echo "📊 Tables in database: $TABLE_COUNT"
          else
            echo "❌ Cannot access production database"
            exit 1
          fi

          echo "✅ Database access verification complete"

      - name: "💾 Create Database Backup"
        id: backup
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
          DB_NAME: ${{ vars.TURSO_PROD_DB_NAME }}
        run: |
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "💾 Creating Production Database Backup"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📊 Database: $DB_NAME"
          echo "📅 Date: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

          # Generate backup filenames with timestamp
          TIMESTAMP=$(date -u '+%Y-%m-%d_%H-%M-%S')
          DB_FILE="backup-prod-${TIMESTAMP}.db"
          BACKUP_FILE="backup-prod-${TIMESTAMP}.sql"
          COMPRESSED_FILE="${BACKUP_FILE}.gz"

          # Export database to SQLite format (reliable for CI/CD)
          echo "📤 Exporting database to SQLite format..."
          turso db export "$DB_NAME" --output-file "$DB_FILE" --overwrite

          # Check if export succeeded
          if [ ! -s "$DB_FILE" ]; then
            echo "❌ Database export failed or is empty"
            exit 1
          fi

          SQLITE_SIZE=$(stat -f%z "$DB_FILE" 2>/dev/null || stat -c%s "$DB_FILE")
          echo "✅ Database exported: $(numfmt --to=iec-i --suffix=B $SQLITE_SIZE || echo ${SQLITE_SIZE}B)"

          # Convert SQLite to SQL format for compatibility
          echo "🔄 Converting to SQL format..."
          sqlite3 "$DB_FILE" .dump > "$BACKUP_FILE"

          # Clean up SQLite files
          rm -f "$DB_FILE" "${DB_FILE}-wal"

          # Verify SQL dump
          if [ ! -s "$BACKUP_FILE" ]; then
            echo "❌ SQL conversion failed or is empty"
            exit 1
          fi

          ORIGINAL_SIZE=$(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE")
          echo "✅ SQL dump created: $(numfmt --to=iec-i --suffix=B $ORIGINAL_SIZE || echo ${ORIGINAL_SIZE}B)"

          # Compress backup
          echo "🗜️  Compressing backup..."
          gzip -9 "$BACKUP_FILE"

          COMPRESSED_SIZE=$(stat -f%z "$COMPRESSED_FILE" 2>/dev/null || stat -c%s "$COMPRESSED_FILE")
          COMPRESSION_RATIO=$(awk "BEGIN {printf \"%.1f\", (1 - $COMPRESSED_SIZE / $ORIGINAL_SIZE) * 100}")

          echo "✅ Backup compressed: $(numfmt --to=iec-i --suffix=B $COMPRESSED_SIZE || echo ${COMPRESSED_SIZE}B) (${COMPRESSION_RATIO}% reduction)"

          # Export variables for next steps
          echo "backup_file=$COMPRESSED_FILE" >> $GITHUB_OUTPUT
          echo "original_size=$ORIGINAL_SIZE" >> $GITHUB_OUTPUT
          echo "compressed_size=$COMPRESSED_SIZE" >> $GITHUB_OUTPUT
          echo "compression_ratio=$COMPRESSION_RATIO" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: "☁️  Upload to Vercel Blob Storage"
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
        run: |
          echo "☁️  Uploading backup to Vercel Blob Storage..."
          node scripts/upload-backup-to-blob.js \
            "${{ steps.backup.outputs.backup_file }}" \
            "prod"

      - name: "🧹 Cleanup Old Backups"
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
        run: |
          echo "🧹 Cleaning up backups older than 30 days..."
          node scripts/cleanup-old-backups.js --retention-days 30

      - name: "📤 Upload Backup Artifact"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-prod-${{ steps.backup.outputs.timestamp }}
          path: ${{ steps.backup.outputs.backup_file }}
          retention-days: 7
          compression-level: 0  # Already compressed with gzip

      - name: "📊 Backup Summary"
        if: always()
        run: |
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📊 Backup Summary - Production"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "✅ Status: ${{ job.status }}"
          echo "📦 Original Size: ${{ steps.backup.outputs.original_size }} bytes"
          echo "🗜️  Compressed Size: ${{ steps.backup.outputs.compressed_size }} bytes"
          echo "📉 Compression: ${{ steps.backup.outputs.compression_ratio }}%"
          echo "📅 Timestamp: ${{ steps.backup.outputs.timestamp }}"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

  backup-development:
    name: "💾 Backup Development"
    runs-on: ubuntu-latest
    timeout-minutes: 15

    # Run on schedule, manual trigger for dev/both, or push/PR events (for testing)
    if: |
      github.event_name == 'schedule' ||
      github.event_name == 'push' ||
      github.event_name == 'pull_request' ||
      github.event.inputs.database == 'both' ||
      github.event.inputs.database == 'dev'

    steps:
      - name: "📥 Checkout Code"
        uses: actions/checkout@v4

      - name: "🔧 Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: "📦 Install Dependencies"
        run: |
          echo "📦 Installing @vercel/blob SDK..."
          npm install @vercel/blob --no-save --no-audit

      - name: "🔧 Install Turso CLI"
        run: |
          echo "🔧 Installing Turso CLI..."
          curl -sSfL https://get.tur.so/install.sh | bash

          # Verify installation
          if [ ! -f "$HOME/.turso/turso" ]; then
            echo "❌ Turso CLI installation failed - binary not found"
            exit 1
          fi

          echo "✅ Turso CLI installed: $(ls -lh $HOME/.turso/turso)"

          # Add to PATH for subsequent steps (correct directory)
          echo "$HOME/.turso" >> $GITHUB_PATH

      - name: "🔐 Verify Turso API Token"
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
        run: |
          echo "🔐 Verifying Turso API token..."

          # Check if token is set
          if [ -z "$TURSO_API_TOKEN" ]; then
            echo "❌ TURSO_API_TOKEN secret is not set"
            echo ""
            echo "📝 Fix: Go to GitHub Settings → Secrets → Actions → New secret"
            echo "   Name: TURSO_API_TOKEN"
            echo "   Value: Run 'turso auth token' to get your platform API token"
            echo ""
            echo "⚠️  Note: TURSO_API_TOKEN (platform token) is different from"
            echo "   TURSO_AUTH_TOKEN (database connection token)"
            exit 1
          fi

          # Verify token format (JWT should start with 'eyJ')
          if [[ ! "$TURSO_API_TOKEN" =~ ^eyJ ]]; then
            echo "⚠️  Warning: Token doesn't appear to be a valid JWT (should start with 'eyJ')"
          fi

          echo "✅ TURSO_API_TOKEN is configured"

      - name: "🔍 Verify Database Access"
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
          DB_NAME: ${{ vars.TURSO_DEV_DB_NAME }}
        run: |
          echo "🔍 Verifying development database access..."

          if turso db show "$DB_NAME" > /dev/null 2>&1; then
            echo "✅ Can access development database"

            # Verify we can query the database
            TABLE_COUNT=$(turso db shell "$DB_NAME" "SELECT COUNT(*) as count FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'" | tail -n 1 | tr -d ' ')
            echo "📊 Tables in database: $TABLE_COUNT"
          else
            echo "❌ Cannot access development database"
            exit 1
          fi

          echo "✅ Database access verification complete"

      - name: "💾 Create Database Backup"
        id: backup
        env:
          TURSO_API_TOKEN: ${{ secrets.TURSO_API_TOKEN }}
          DB_NAME: ${{ vars.TURSO_DEV_DB_NAME }}
        run: |
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "💾 Creating Development Database Backup"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📊 Database: $DB_NAME"
          echo "📅 Date: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

          # Generate backup filenames with timestamp
          TIMESTAMP=$(date -u '+%Y-%m-%d_%H-%M-%S')
          DB_FILE="backup-dev-${TIMESTAMP}.db"
          BACKUP_FILE="backup-dev-${TIMESTAMP}.sql"
          COMPRESSED_FILE="${BACKUP_FILE}.gz"

          # Export database to SQLite format (reliable for CI/CD)
          echo "📤 Exporting database to SQLite format..."
          turso db export "$DB_NAME" --output-file "$DB_FILE" --overwrite

          # Check if export succeeded
          if [ ! -s "$DB_FILE" ]; then
            echo "❌ Database export failed or is empty"
            exit 1
          fi

          SQLITE_SIZE=$(stat -f%z "$DB_FILE" 2>/dev/null || stat -c%s "$DB_FILE")
          echo "✅ Database exported: $(numfmt --to=iec-i --suffix=B $SQLITE_SIZE || echo ${SQLITE_SIZE}B)"

          # Convert SQLite to SQL format for compatibility
          echo "🔄 Converting to SQL format..."
          sqlite3 "$DB_FILE" .dump > "$BACKUP_FILE"

          # Clean up SQLite files
          rm -f "$DB_FILE" "${DB_FILE}-wal"

          # Verify SQL dump
          if [ ! -s "$BACKUP_FILE" ]; then
            echo "❌ SQL conversion failed or is empty"
            exit 1
          fi

          ORIGINAL_SIZE=$(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE")
          echo "✅ SQL dump created: $(numfmt --to=iec-i --suffix=B $ORIGINAL_SIZE || echo ${ORIGINAL_SIZE}B)"

          # Compress backup
          echo "🗜️  Compressing backup..."
          gzip -9 "$BACKUP_FILE"

          COMPRESSED_SIZE=$(stat -f%z "$COMPRESSED_FILE" 2>/dev/null || stat -c%s "$COMPRESSED_FILE")
          COMPRESSION_RATIO=$(awk "BEGIN {printf \"%.1f\", (1 - $COMPRESSED_SIZE / $ORIGINAL_SIZE) * 100}")

          echo "✅ Backup compressed: $(numfmt --to=iec-i --suffix=B $COMPRESSED_SIZE || echo ${COMPRESSED_SIZE}B) (${COMPRESSION_RATIO}% reduction)"

          # Export variables for next steps
          echo "backup_file=$COMPRESSED_FILE" >> $GITHUB_OUTPUT
          echo "original_size=$ORIGINAL_SIZE" >> $GITHUB_OUTPUT
          echo "compressed_size=$COMPRESSED_SIZE" >> $GITHUB_OUTPUT
          echo "compression_ratio=$COMPRESSION_RATIO" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: "☁️  Upload to Vercel Blob Storage"
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
        run: |
          echo "☁️  Uploading backup to Vercel Blob Storage..."
          node scripts/upload-backup-to-blob.js \
            "${{ steps.backup.outputs.backup_file }}" \
            "dev"

      - name: "🧹 Cleanup Old Backups"
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
        run: |
          echo "🧹 Cleaning up backups older than 30 days..."
          node scripts/cleanup-old-backups.js --retention-days 30

      - name: "📤 Upload Backup Artifact"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-dev-${{ steps.backup.outputs.timestamp }}
          path: ${{ steps.backup.outputs.backup_file }}
          retention-days: 7
          compression-level: 0  # Already compressed with gzip

      - name: "📊 Backup Summary"
        if: always()
        run: |
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📊 Backup Summary - Development"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "✅ Status: ${{ job.status }}"
          echo "📦 Original Size: ${{ steps.backup.outputs.original_size }} bytes"
          echo "🗜️  Compressed Size: ${{ steps.backup.outputs.compressed_size }} bytes"
          echo "📉 Compression: ${{ steps.backup.outputs.compression_ratio }}%"
          echo "📅 Timestamp: ${{ steps.backup.outputs.timestamp }}"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

  notify:
    name: "📧 Notify on Failure"
    runs-on: ubuntu-latest
    needs: [backup-production, backup-development]
    if: always() && (needs.backup-production.result == 'failure' || needs.backup-development.result == 'failure')

    steps:
      - name: "📧 Send Failure Notification"
        run: |
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "❌ BACKUP FAILURE NOTIFICATION"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "⏰ Time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "🔗 Workflow: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo ""
          echo "⚠️  Daily database backup failed!"
          echo "   Please check the workflow logs and investigate immediately."
          echo ""
          echo "🔍 Common Issues:"
          echo "   - Turso authentication failure (check TURSO_AUTH_TOKEN)"
          echo "   - Vercel Blob upload failure (check BLOB_READ_WRITE_TOKEN)"
          echo "   - Database connectivity issues"
          echo "   - Insufficient storage quota"
          echo ""
          echo "📚 See docs/DISASTER_RECOVERY.md for troubleshooting guidance"
