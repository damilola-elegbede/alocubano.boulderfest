name: 'Collect Test Results'
description: 'Collects and processes test results for comprehensive reporting'
inputs:
  test-type:
    description: 'Type of test (unit, e2e, performance, security)'
    required: true
  test-results-path:
    description: 'Path to test results files'
    required: false
    default: 'test-results'
  coverage-path:
    description: 'Path to coverage files'
    required: false
    default: 'coverage'
  include-performance:
    description: 'Include performance metrics'
    required: false
    default: 'false'
  browser-name:
    description: 'Browser name for E2E tests'
    required: false
    default: ''
  job-start-time:
    description: 'Job start time in epoch seconds'
    required: false
    default: ''

outputs:
  test-summary:
    description: 'JSON summary of test results'
    value: ${{ steps.process.outputs.summary }}
  status:
    description: 'Overall test status (success, failure, warning)'
    value: ${{ steps.process.outputs.status }}
  execution-time:
    description: 'Test execution time in seconds'
    value: ${{ steps.process.outputs.execution_time }}
  test-count:
    description: 'Total number of tests'
    value: ${{ steps.process.outputs.test_count }}
  passed-count:
    description: 'Number of passed tests'
    value: ${{ steps.process.outputs.passed_count }}
  failed-count:
    description: 'Number of failed tests'
    value: ${{ steps.process.outputs.failed_count }}
  skipped-count:
    description: 'Number of skipped tests'
    value: ${{ steps.process.outputs.skipped_count }}
  coverage-percentage:
    description: 'Test coverage percentage'
    value: ${{ steps.process.outputs.coverage }}
  flaky-tests:
    description: 'List of flaky tests detected'
    value: ${{ steps.process.outputs.flaky_tests }}

runs:
  using: 'composite'
  steps:
    - name: Process Test Results
      id: process
      shell: bash
      run: |
        TEST_TYPE="${{ inputs.test-type }}"
        RESULTS_PATH="${{ inputs.test-results-path }}"
        COVERAGE_PATH="${{ inputs.coverage-path }}"
        BROWSER="${{ inputs.browser-name }}"
        START_TIME="${{ inputs.job-start-time }}"
        
        echo "ðŸ” Processing $TEST_TYPE test results..."
        
        # Initialize default values
        STATUS="success"
        EXECUTION_TIME="0"
        TEST_COUNT="0"
        PASSED_COUNT="0"
        FAILED_COUNT="0"
        SKIPPED_COUNT="0"
        COVERAGE="0"
        FLAKY_TESTS="[]"
        
        # Calculate execution time if start time provided
        if [ -n "$START_TIME" ] && [ "$START_TIME" -gt 0 ]; then
          END_TIME=$(date +%s)
          EXECUTION_TIME=$((END_TIME - START_TIME))
        fi
        
        # Process results based on test type
        case "$TEST_TYPE" in
          "unit")
            echo "ðŸ“Š Processing unit test results..."
            
            # Look for Vitest results
            if [ -f "test-results.json" ]; then
              TEST_COUNT=$(jq -r '.numTotalTests // 0' test-results.json 2>/dev/null || echo "0")
              PASSED_COUNT=$(jq -r '.numPassedTests // 0' test-results.json 2>/dev/null || echo "0")
              FAILED_COUNT=$(jq -r '.numFailedTests // 0' test-results.json 2>/dev/null || echo "0")
              SKIPPED_COUNT=$(jq -r '.numPendingTests // 0' test-results.json 2>/dev/null || echo "0")
            fi
            
            # Look for coverage information
            if [ -f "$COVERAGE_PATH/coverage-summary.json" ]; then
              COVERAGE=$(jq -r '.total.lines.pct // 0' "$COVERAGE_PATH/coverage-summary.json" 2>/dev/null || echo "0")
            fi
            
            # Check for failures
            if [ "$FAILED_COUNT" -gt 0 ]; then
              STATUS="failure"
            fi
            ;;
            
          "e2e")
            echo "ðŸ“Š Processing E2E test results for $BROWSER..."
            
            # Look for Playwright results
            if [ -f "$RESULTS_PATH/results.json" ]; then
              TOTAL_SUITES=$(jq '[.suites[].specs[]] | length' "$RESULTS_PATH/results.json" 2>/dev/null || echo "0")
              PASSED_TESTS=$(jq '[.suites[].specs[] | select(.ok == true)] | length' "$RESULTS_PATH/results.json" 2>/dev/null || echo "0")
              FAILED_TESTS=$(jq '[.suites[].specs[] | select(.ok == false)] | length' "$RESULTS_PATH/results.json" 2>/dev/null || echo "0")
              
              TEST_COUNT=$TOTAL_SUITES
              PASSED_COUNT=$PASSED_TESTS
              FAILED_COUNT=$FAILED_TESTS
              
              # Detect flaky tests (tests that passed after retry)
              FLAKY_TESTS=$(jq -r '[.suites[].specs[] | select(.tests[].results[] | .retry > 0 and .status == "passed") | .title] | @json' "$RESULTS_PATH/results.json" 2>/dev/null || echo "[]")
            fi
            
            # Alternative: parse from console output
            if [ "$TEST_COUNT" -eq 0 ] && [ -f "playwright-output.log" ]; then
              TEST_COUNT=$(grep -o "[0-9]\+ passed" playwright-output.log | head -1 | grep -o "[0-9]\+" || echo "0")
              PASSED_COUNT=$TEST_COUNT
              FAILED_COUNT=$(grep -o "[0-9]\+ failed" playwright-output.log | head -1 | grep -o "[0-9]\+" || echo "0")
              SKIPPED_COUNT=$(grep -o "[0-9]\+ skipped" playwright-output.log | head -1 | grep -o "[0-9]\+" || echo "0")
            fi
            
            if [ "$FAILED_COUNT" -gt 0 ]; then
              STATUS="failure"
            fi
            ;;
            
          "performance")
            echo "ðŸ“Š Processing performance test results..."
            
            if [ -f "$RESULTS_PATH/performance-results.json" ]; then
              # Extract performance metrics
              AVG_RESPONSE_TIME=$(jq -r '.http_req_duration.avg // 0' "$RESULTS_PATH/performance-results.json" 2>/dev/null || echo "0")
              P95_RESPONSE_TIME=$(jq -r '.http_req_duration."p(95)" // 0' "$RESULTS_PATH/performance-results.json" 2>/dev/null || echo "0")
              ERROR_RATE=$(jq -r '.http_req_failed.rate // 0' "$RESULTS_PATH/performance-results.json" 2>/dev/null || echo "0")
              
              # Performance tests are considered failed if error rate > 1% or P95 > 2000ms
              if (( $(echo "$ERROR_RATE > 0.01" | bc -l 2>/dev/null || echo "0") )) || (( $(echo "$P95_RESPONSE_TIME > 2000" | bc -l 2>/dev/null || echo "0") )); then
                STATUS="failure"
                FAILED_COUNT=1
              else
                PASSED_COUNT=1
              fi
              TEST_COUNT=1
            fi
            ;;
            
          "security")
            echo "ðŸ“Š Processing security test results..."
            
            if [ -f "audit-output.log" ]; then
              VULNERABILITIES=$(grep -c "vulnerabilities" audit-output.log || echo "0")
              CRITICAL_ISSUES=$(grep -c "critical" audit-output.log || echo "0")
              
              if [ "$CRITICAL_ISSUES" -gt 0 ]; then
                STATUS="failure"
                FAILED_COUNT=$CRITICAL_ISSUES
              elif [ "$VULNERABILITIES" -gt 0 ]; then
                STATUS="warning"
              fi
              
              TEST_COUNT=1
              PASSED_COUNT=$((1 - FAILED_COUNT))
            fi
            ;;
        esac
        
        # Create summary JSON
        SUMMARY=$(cat <<EOF
        {
          "type": "$TEST_TYPE",
          "browser": "$BROWSER",
          "status": "$STATUS",
          "execution_time": $EXECUTION_TIME,
          "test_count": $TEST_COUNT,
          "passed_count": $PASSED_COUNT,
          "failed_count": $FAILED_COUNT,
          "skipped_count": $SKIPPED_COUNT,
          "coverage": "$COVERAGE",
          "flaky_tests": $FLAKY_TESTS,
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        }
        EOF
        )
        
        # Set outputs
        echo "summary=$(echo "$SUMMARY" | jq -c .)" >> $GITHUB_OUTPUT
        echo "status=$STATUS" >> $GITHUB_OUTPUT
        echo "execution_time=$EXECUTION_TIME" >> $GITHUB_OUTPUT
        echo "test_count=$TEST_COUNT" >> $GITHUB_OUTPUT
        echo "passed_count=$PASSED_COUNT" >> $GITHUB_OUTPUT
        echo "failed_count=$FAILED_COUNT" >> $GITHUB_OUTPUT
        echo "skipped_count=$SKIPPED_COUNT" >> $GITHUB_OUTPUT
        echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
        echo "flaky_tests=$FLAKY_TESTS" >> $GITHUB_OUTPUT
        
        echo "âœ… Test results processed: $STATUS (${PASSED_COUNT}/${TEST_COUNT} passed)"