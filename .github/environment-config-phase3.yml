# ======================================================================
# Environment Configuration - Phase 3 Three-Layer Test Architecture
# ======================================================================
# ENVIRONMENT-SPECIFIC OPTIMIZATIONS:
# - Layer-specific memory and timeout configurations
# - CI resource optimization for 806+ unit tests
# - Integration test environment variables and setup
# - E2E test browser and deployment configurations
# - Performance monitoring and alerting thresholds
# ======================================================================

# Three-Layer Test Architecture Configuration
test_layers:
  layer_1_unit:
    name: "Unit Tests"
    description: "806+ isolated unit tests with mocks"
    target_count: 806
    target_execution_time_ms: 2000
    memory_allocation_mb: 6144
    timeout_configurations:
      test_timeout_ms: 10000
      hook_timeout_ms: 8000
      setup_timeout_ms: 8000
      cleanup_timeout_ms: 5000
    concurrency:
      ci_max_concurrency: 1
      local_max_concurrency: 5
    retry_policy:
      ci_retries: 1
      local_retries: 0
    required_for_deployment: true
    
  layer_2_integration:
    name: "Integration Tests"
    description: "30-50 API and database integration tests"
    target_count: 30
    target_execution_time_ms: 30000
    memory_allocation_mb: 4096
    timeout_configurations:
      test_timeout_ms: 60000
      hook_timeout_ms: 30000
      setup_timeout_ms: 20000
      cleanup_timeout_ms: 10000
    concurrency:
      ci_max_concurrency: 1
      local_max_concurrency: 3
    retry_policy:
      ci_retries: 2
      local_retries: 1
    required_for_deployment: false
    enabled_by_default: false
    
  layer_3_e2e:
    name: "E2E Tests"
    description: "12 comprehensive end-to-end browser tests"
    target_count: 12
    target_execution_time_ms: 300000
    memory_allocation_mb: 3072
    timeout_configurations:
      test_timeout_ms: 60000
      action_timeout_ms: 30000
      navigation_timeout_ms: 60000
      expect_timeout_ms: 10000
      health_check_interval_ms: 5000
    concurrency:
      ci_max_parallel: 2
      local_max_parallel: 1
    retry_policy:
      ci_retries: 2
      local_retries: 1
    required_for_deployment: false
    trigger_condition: "pull_request"

# Environment-Specific Configurations
environments:
  ci:
    name: "Continuous Integration"
    node_options_base: "--max-old-space-size="
    database_url: "file:./data/ci-test.db"
    cache_strategy: "aggressive"
    npm_install_flags: "--prefer-offline --no-audit"
    performance_monitoring: true
    resource_limits:
      max_build_time_minutes: 20
      max_test_time_minutes: 15
      max_deployment_time_minutes: 10
    
  production_gate:
    name: "Production Deployment Gate"
    node_options_base: "--max-old-space-size="
    database_url: "file:./data/production-gate-test.db"
    cache_strategy: "minimal"
    npm_install_flags: "--prefer-offline --no-audit"
    performance_monitoring: true
    strict_thresholds: true
    zero_tolerance_failures: ["unit_tests", "performance_gate", "security_gate"]
    
  e2e:
    name: "End-to-End Testing"
    node_options_base: "--max-old-space-size="
    database_environment: "preview_deployment"
    browser_configs:
      chromium:
        timeout_minutes: 15
        retry_count: 2
        memory_limit_mb: 4096
      firefox:
        timeout_minutes: 18
        retry_count: 3
        memory_limit_mb: 5120
      webkit:
        timeout_minutes: 20
        retry_count: 3
        memory_limit_mb: 4096
    
  monitoring:
    name: "Test Monitoring & Observability"
    node_options_base: "--max-old-space-size="
    database_url: "file:./data/monitoring-test.db"
    analysis_configurations:
      performance_monitoring_runs: 3
      success_rate_analysis_runs: 5
      failure_pattern_detection: true
      alert_generation: true

# Performance Thresholds and Targets
performance_targets:
  unit_tests:
    excellent_threshold_ms: 1500
    good_threshold_ms: 2000
    needs_improvement_threshold_ms: 3000
    critical_threshold_ms: 5000
    minimum_success_rate_percent: 94
    minimum_coverage_percent: 75
    
  integration_tests:
    excellent_threshold_ms: 20000
    good_threshold_ms: 30000
    needs_improvement_threshold_ms: 60000
    critical_threshold_ms: 120000
    minimum_success_rate_percent: 90
    minimum_coverage_percent: 70
    
  e2e_tests:
    excellent_threshold_ms: 180000
    good_threshold_ms: 300000
    needs_improvement_threshold_ms: 480000
    critical_threshold_ms: 600000
    minimum_success_rate_percent: 85
    browser_timeout_multiplier: 1.2

# Resource Optimization Configurations
resource_optimization:
  memory_allocation:
    unit_tests_mb: 6144    # For 806+ tests with mocks
    integration_tests_mb: 4096  # For API/DB interactions
    e2e_tests_mb: 3072     # Per browser instance
    monitoring_mb: 4096    # For analysis and reporting
    
  concurrency_limits:
    unit_tests_ci: 1       # Single-threaded for reliability
    unit_tests_local: 5    # Multi-threaded for speed
    integration_tests_ci: 1  # Sequential for DB safety
    integration_tests_local: 3  # Limited parallelism
    e2e_tests_ci: 2        # Browser resource management
    e2e_tests_local: 1     # Single browser for stability
    
  timeout_multipliers:
    ci_environment: 1.5    # 50% longer timeouts in CI
    local_environment: 1.0  # Standard timeouts locally
    debugging_mode: 3.0    # 3x longer for debugging
    
  caching_strategies:
    npm_cache_aggressive: "--prefer-offline --no-audit --ignore-scripts"
    npm_cache_standard: "--prefer-offline --no-audit"
    npm_cache_minimal: "--no-audit"

# Quality Gates and Deployment Safeguards
quality_gates:
  mandatory_gates:
    - name: "unit_tests"
      description: "All unit tests must pass"
      failure_action: "block_deployment"
      bypass_allowed: false
      
    - name: "performance_gate"
      description: "Unit tests must execute in <2 seconds"
      failure_action: "block_deployment"
      bypass_allowed: "emergency_only"
      
    - name: "environment_validation"
      description: "CI environment must be properly configured"
      failure_action: "block_deployment"
      bypass_allowed: false
      
  optional_gates:
    - name: "integration_tests"
      description: "Integration tests (when enabled)"
      failure_action: "warn"
      bypass_allowed: true
      
    - name: "security_audit"
      description: "No high-severity vulnerabilities"
      failure_action: "warn"
      bypass_allowed: "with_justification"
      
    - name: "code_quality_lint"
      description: "Linting standards compliance"
      failure_action: "warn"
      bypass_allowed: "with_justification"
      
    - name: "build_verification"
      description: "Successful production build"
      failure_action: "warn"
      bypass_allowed: "degraded_mode"

# Monitoring and Alerting Configuration
monitoring:
  alert_thresholds:
    unit_test_failure_rate_percent: 5
    integration_test_failure_rate_percent: 10
    e2e_test_failure_rate_percent: 15
    performance_degradation_percent: 20
    
  monitoring_schedules:
    business_hours_cron: "0 8-20 * * 1-5"  # Every hour 8 AM - 8 PM, Monday - Friday
    nightly_analysis_cron: "0 2 * * *"     # Daily at 2 AM
    weekly_report_cron: "0 9 * * 1"        # Monday at 9 AM
    
  analysis_periods:
    short_term_hours: 4
    medium_term_hours: 24
    long_term_hours: 168  # 1 week
    
  retention_policies:
    test_results_days: 7
    monitoring_data_days: 14
    performance_metrics_days: 30
    alert_history_days: 90

# CI/CD Pipeline Configuration
pipeline_optimization:
  parallel_execution:
    validation_and_unit_tests: true
    validation_and_build: true
    validation_and_quality_gates: true
    unit_tests_and_build: false  # Unit tests are deployment gate
    
  dependency_chains:
    critical_path: ["environment_validation", "unit_tests", "deployment_gate"]
    quality_path: ["build_verification", "security_audit", "lint_checks"]
    integration_path: ["unit_tests", "integration_tests", "deployment_readiness"]
    e2e_path: ["build_success", "preview_deployment", "e2e_tests"]
    
  failure_handling:
    fail_fast_critical: true
    continue_on_quality_issues: true
    retry_transient_failures: true
    aggregate_failure_reporting: true
    
  artifact_management:
    test_results_retention_days: 7
    coverage_reports_retention_days: 14
    monitoring_dashboards_retention_days: 14
    production_gate_results_retention_days: 30

# Integration Points
integration:
  vercel_deployments:
    preview_deployment_trigger: "pull_request"
    production_deployment_trigger: "push_to_main"
    deployment_health_checks: true
    rollback_on_failure: true
    
  github_actions:
    workflow_concurrency_groups: true
    cancel_in_progress: true
    status_checks_required: ["unit-tests", "production-deployment-gate"]
    status_checks_optional: ["integration-tests", "e2e-tests"]
    
  monitoring_integrations:
    github_status_api: true
    step_summary_dashboards: true
    artifact_uploads: true
    alert_notifications: false  # Configure based on team preferences